{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d26a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# NOTE: Whichever package you want mention here.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell' \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dae381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Transaction Data Cleaning\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# On yarn:\n",
    "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
    "# specify .master(\"yarn\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26de1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import DecimalType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f7ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the parquet file from hdfs to perform data cleaning\n",
    "df = spark.read.parquet('/user/talentum/projectMaster/dataStaging/credit_card_transactions-ibm_v2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7508ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing '$' from the amount column and converting it to float data type\n",
    "df_cleaning = df.withColumn('Amount', F.regexp_replace(F.col('Amount'), '[$,]', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92987709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casting the Amount cloumn to Float(10,2)\n",
    "df_cleaned = df_cleaning.withColumn(\n",
    "    'Amount',\n",
    "    F.col('Amount').cast(DecimalType(10, 2))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "354daaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing word Transaction from the field Use_Chip\n",
    "df_cleaning = df_cleaning.withColumn('Use_Chip', F.regexp_replace(F.col('Use_Chip'), ' Transaction', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9255bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing null with a placeholder 'N/A'\n",
    "df_cleaning = df_cleaning.fillna('N/A', subset=['Errors?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6485fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casting Zip to string type\n",
    "df_cleaning = df_cleaning.withColumn(\"Zip\", \n",
    "    F.coalesce(\n",
    "        # Robust conversion: Cast float to int to safely remove .0, then pad to 5 digits\n",
    "        F.lpad(F.col(\"Zip\").cast(\"float\").cast(\"int\").cast(\"string\"), 5, \"0\"), \n",
    "        F.lit(\"00000\") # Fill Null/Missing Zip codes with '00000'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c2b3020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a Date_str column to also have consolidated dates\n",
    "df_cleaning = df_cleaning.withColumn(\n",
    "    # Create the date string: YYYY-MM-DD\n",
    "    \"Date_Str\",\n",
    "    F.concat_ws(\"-\",\n",
    "        F.col(\"Year\"),\n",
    "        # Pad Month and Day to ensure 2 digits (e.g., 8 -> 08) for standard format\n",
    "        F.lpad(F.col(\"Month\").cast(\"string\"), 2, \"0\"),\n",
    "        F.lpad(F.col(\"Day\").cast(\"string\"), 2, \"0\")\n",
    "    )\n",
    ").withColumn(\n",
    "    # Combine Date_Str and Time into a single TIMESTAMP object\n",
    "    \"Transaction_Timestamp\",\n",
    "    F.to_timestamp(F.concat(F.col(\"Date_Str\"), F.lit(\" \"), F.col(\"Time\")), \"yyyy-MM-dd HH:mm\")\n",
    ").drop(\"Year\", \"Month\", \"Day\", \"Time\", \"Date_Str\") # Drop original raw columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2270f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-------+--------+--------------------+--------------+--------------+-----+----+-------+---------+---------------------+\n",
      "|User|Card| Amount|Use_Chip|       Merchant_Name| Merchant_City|Merchant_State|  Zip| MCC|Errors?|Is_Fraud?|Transaction_Timestamp|\n",
      "+----+----+-------+--------+--------------------+--------------+--------------+-----+----+-------+---------+---------------------+\n",
      "| 591|   3|-415.00|    Chip| 4552887027432897467|       Oakland|            CA|94606|3596|    N/A|       No|  2016-08-13 10:54:00|\n",
      "| 591|   3|  22.37|    Chip|-8964802287130046767|        Tucker|            GA|30084|7230|    N/A|       No|  2016-08-16 13:33:00|\n",
      "| 591|   3|  10.87|    Chip|   97032797689821735|Southern Pines|            NC|28387|5411|    N/A|       No|  2016-08-19 14:38:00|\n",
      "| 591|   3|  73.84|    Chip|-5401953891366957779|       Shannon|            NC|28386|5651|    N/A|       No|  2016-08-20 10:11:00|\n",
      "| 591|   3|  38.50|    Chip|-2472481739355111587|   Saint Pauls|            NC|28384|7538|    N/A|       No|  2016-08-20 15:32:00|\n",
      "+----+----+-------+--------+--------------------+--------------+--------------+-----+----+-------+---------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaning.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e99ced03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User: integer (nullable = true)\n",
      " |-- Card: integer (nullable = true)\n",
      " |-- Amount: string (nullable = true)\n",
      " |-- Use_Chip: string (nullable = true)\n",
      " |-- Merchant_Name: long (nullable = true)\n",
      " |-- Merchant_City: string (nullable = true)\n",
      " |-- Merchant_State: string (nullable = true)\n",
      " |-- Zip: string (nullable = false)\n",
      " |-- MCC: integer (nullable = true)\n",
      " |-- Errors?: string (nullable = false)\n",
      " |-- Is_Fraud?: string (nullable = true)\n",
      " |-- Transaction_Timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaning.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf850dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Done !!!!\n"
     ]
    }
   ],
   "source": [
    "#saving this cleaned parquet to a warehouseDir to be used by hive warehouse for OLAP purpose\n",
    "df_cleaning.write.mode(\"overwrite\").parquet('/user/talentum/projectMaster/warehouseDir/transactions')\n",
    "print('Job Done !!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb87b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
