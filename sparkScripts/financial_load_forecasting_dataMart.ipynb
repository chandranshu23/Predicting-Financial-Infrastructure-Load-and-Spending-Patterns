{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76320b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Intialization\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# NOTE: Whichever package you want mention here.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell' \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a1b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"create_merchant_recommendation_dataMart\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# On yarn:\n",
    "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
    "# specify .master(\"yarn\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "426a5b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Config Updated for maximum stability.\n"
     ]
    }
   ],
   "source": [
    "# 1. Disable Vectorized Reader (Avoids low-level ORC data reading crash)\n",
    "spark.conf.set(\"spark.sql.orc.enableVectorizedReader\", \"false\")\n",
    "spark.conf.set(\"spark.sql.hive.convertMetastoreOrc\", \"false\")\n",
    "# 2. Disable Broadcast Join (Avoids memory/shuffle crash on join)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1) \n",
    "# 3. Disable Spark's optimizing components (Forces safer execution path)\n",
    "spark.conf.set(\"spark.sql.cbo.enabled\", \"false\") \n",
    "spark.conf.set(\"spark.sql.codegen.wholeStage\", \"false\")\n",
    "# 4. Force Hive SerDe (Ultimate attempt to bypass native Spark reader)\n",
    "spark.conf.set(\"spark.sql.hive.convertMetastore\", \"false\") \n",
    "\n",
    "print(\"Spark Config Updated for maximum stability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe83aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import DecimalType, LongType, IntegerType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a7fa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Silver Layer tables from Hive...\n",
      "Loading command executed\n"
     ]
    }
   ],
   "source": [
    "# Load the Tables directly from the Database\n",
    "# We use the standard 'database_name.table_name' format\n",
    "\n",
    "print(\"Loading Silver Layer tables from Hive...\")\n",
    "\n",
    "# A. Transactions Table\n",
    "df_trans_silver = spark.table(\"financial_db.transactions_silver\")\n",
    "\n",
    "# B. Users Table\n",
    "df_users_silver = spark.table(\"financial_db.users_silver\")\n",
    "\n",
    "# C. Cards Table\n",
    "df_cards_silver = spark.table(\"financial_db.cards_silver\")\n",
    "\n",
    "print(\"Loading command executed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a90cd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions Count: 24386900\n",
      "Users Count: 2000\n",
      "Cards Count: 6146\n"
     ]
    }
   ],
   "source": [
    "# run only if you are not sure the files are loaded\n",
    "# Quick Verification\n",
    "print(f\"Transactions Count: {df_trans_silver.count()}\")\n",
    "print(f\"Users Count: {df_users_silver.count()}\")\n",
    "print(f\"Cards Count: {df_cards_silver.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d8a0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- card_id: integer (nullable = true)\n",
      " |-- amount: decimal(10,2) (nullable = true)\n",
      " |-- use_chip: string (nullable = true)\n",
      " |-- merchant_name: string (nullable = true)\n",
      " |-- merchant_city: string (nullable = true)\n",
      " |-- merchant_state: string (nullable = true)\n",
      " |-- zip: string (nullable = true)\n",
      " |-- mcc: integer (nullable = true)\n",
      " |-- errors: string (nullable = true)\n",
      " |-- is_fraud: string (nullable = true)\n",
      " |-- transaction_timestamp: timestamp (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- person_id: string (nullable = true)\n",
      " |-- current_age: integer (nullable = true)\n",
      " |-- retirement_age: integer (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- birth_month: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- apartment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- per_capita_income_zipcode: decimal(10,2) (nullable = true)\n",
      " |-- yearly_income_person: decimal(10,2) (nullable = true)\n",
      " |-- total_debt: decimal(10,2) (nullable = true)\n",
      " |-- fico_score: integer (nullable = true)\n",
      " |-- num_credit_cards: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- card_index: integer (nullable = true)\n",
      " |-- card_brand: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- card_number: integer (nullable = true)\n",
      " |-- expires: string (nullable = true)\n",
      " |-- cvv: integer (nullable = true)\n",
      " |-- has_chip: string (nullable = true)\n",
      " |-- cards_issued: integer (nullable = true)\n",
      " |-- credit_limit: decimal(10,2) (nullable = true)\n",
      " |-- year_pin_last_changed: integer (nullable = true)\n",
      " |-- card_on_dark_web: string (nullable = true)\n",
      " |-- acct_opened_month: integer (nullable = true)\n",
      " |-- acct_opened_year: integer (nullable = true)\n",
      " |-- expires_month: integer (nullable = true)\n",
      " |-- expires_year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Previewing Schema to ensure types are correct\n",
    "df_trans_silver.printSchema()\n",
    "df_users_silver.printSchema()\n",
    "df_cards_silver.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e54b48e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Renaming and Preparing DataFrames ---\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. Renaming & Preparation (Golden Layer Prep)\n",
    "# ==========================================\n",
    "print(\"--- Step 1: Renaming and Preparing DataFrames ---\")\n",
    "\n",
    "# --- A. Transactions Prep ---\n",
    "# Already has snake_case, but ensuring we have the time components needed\n",
    "df_trans_renamed = df_trans_silver.withColumnRenamed(\"zip\", \"merchant_zip\") \\\n",
    "    .withColumnRenamed(\"errors\", \"transaction_errors\") \\\n",
    "    .withColumn(\"day\", F.dayofmonth(F.col(\"transaction_timestamp\"))) \\\n",
    "    .withColumn(\"time\", F.date_format(F.col(\"transaction_timestamp\"), \"HH:mm:ss\"))\n",
    "\n",
    "# --- B. Users Prep ---\n",
    "# 1. Generate 'user_id' via Indexing (Crucial for joining)\n",
    "rdd_with_id = df_users_silver.rdd.zipWithIndex().map(lambda x: (x[1],) + tuple(x[0]))\n",
    "user_cols = [\"user_id\"] + df_users_silver.columns\n",
    "df_users_indexed = spark.createDataFrame(rdd_with_id, user_cols)\n",
    "\n",
    "# 2. Rename columns to your convenience\n",
    "df_users_renamed = df_users_indexed \\\n",
    "    .withColumnRenamed(\"current_age\", \"age\") \\\n",
    "    .withColumnRenamed(\"city\", \"user_city\") \\\n",
    "    .withColumnRenamed(\"state\", \"user_state\") \\\n",
    "    .withColumnRenamed(\"per_capita_income_zipcode\", \"per_capita_income\") \\\n",
    "    .withColumnRenamed(\"yearly_income_person\", \"yearly_income\") \\\n",
    "    .withColumnRenamed(\"total_debt\", \"total_debt\")\n",
    "\n",
    "# --- C. Cards Prep ---\n",
    "# Rename keys to match Transactions and create Date for Age Calculation\n",
    "df_cards_renamed = df_cards_silver \\\n",
    "    .withColumnRenamed(\"user\", \"user_id\") \\\n",
    "    .withColumnRenamed(\"card_index\", \"card_id\") \\\n",
    "    .withColumnRenamed(\"card_on_dark_web\", \"dark_web_exposure\") \\\n",
    "    .withColumnRenamed(\"acct_opened_year\", \"acct_year\") \\\n",
    "    .withColumnRenamed(\"acct_opened_month\", \"acct_month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29d960b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 2: Joining Transactions with Users ---\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 2. Join Transactions with Users\n",
    "# ==========================================\n",
    "print(\"--- Step 2: Joining Transactions with Users ---\")\n",
    "\n",
    "df_join_users = df_trans_renamed.join(\n",
    "    df_users_renamed,\n",
    "    on=\"user_id\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c439cb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 3: Selecting Specific User & Transaction Columns ---\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. First Selection (Intermediate DataFrame)\n",
    "# ==========================================\n",
    "print(\"--- Step 3: Selecting Specific User & Transaction Columns ---\")\n",
    "\n",
    "df_resultant = df_join_users.select(\n",
    "    # Keys\n",
    "    F.col(\"user_id\"),\n",
    "    F.col(\"card_id\"),\n",
    "    \n",
    "    # Time\n",
    "    F.col(\"year\"),\n",
    "    F.col(\"month\"),\n",
    "    F.col(\"day\"),\n",
    "    F.col(\"time\"),\n",
    "    F.col(\"transaction_timestamp\"), # Keeping for calculation\n",
    "    \n",
    "    # User Demographics\n",
    "    F.col(\"age\"),\n",
    "    F.col(\"gender\"),\n",
    "    F.col(\"user_city\").alias(\"city\"),\n",
    "    F.col(\"user_state\").alias(\"state\"),\n",
    "    F.col(\"per_capita_income\"),\n",
    "    F.col(\"yearly_income\"),\n",
    "    F.col(\"fico_score\"),\n",
    "    F.col(\"num_credit_cards\"),\n",
    "    F.col(\"total_debt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35e43957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 4: Joining with Cards (on user_id AND card_id) ---\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. Join with Cards\n",
    "# ==========================================\n",
    "print(\"--- Step 4: Joining with Cards (on user_id AND card_id) ---\")\n",
    "# Note: We must join on User ID too, because Card ID 0 belongs to User 0, User 1, etc.\n",
    "\n",
    "df_join_cards = df_resultant.join(\n",
    "    df_cards_renamed,\n",
    "    on=[\"user_id\", \"card_id\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81f2dbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 5: Final Selection & Creating 'Age of Card' ---\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 5. Final Selection & Feature Engineering\n",
    "# ==========================================\n",
    "print(\"--- Step 5: Final Selection & Creating 'Age of Card' ---\")\n",
    "\n",
    "# Calculate Age of Card in Years (Transaction Year - Account Open Year)\n",
    "# We use the columns joined from the Cards table\n",
    "df_final = df_join_cards.withColumn(\n",
    "    \"age_of_card_years\",\n",
    "    F.col(\"year\") - F.col(\"acct_year\")\n",
    ").select(\n",
    "    # Previous Columns\n",
    "    F.col(\"user_id\"),\n",
    "    F.col(\"card_id\"),\n",
    "    F.col(\"age\").alias(\"user_age\"),\n",
    "    F.col(\"gender\"),\n",
    "    F.col(\"city\"),\n",
    "    F.col(\"state\"),\n",
    "    F.col(\"per_capita_income\"),\n",
    "    F.col(\"yearly_income\"),\n",
    "    F.col(\"fico_score\"),\n",
    "    F.col(\"num_credit_cards\"),\n",
    "    F.col(\"total_debt\"),\n",
    "    F.col(\"year\"),\n",
    "    F.col(\"month\"),\n",
    "    F.col(\"day\"),\n",
    "    F.col(\"time\"),\n",
    "    \n",
    "    # Card Specific Columns\n",
    "    F.col(\"card_type\"),\n",
    "    F.col(\"credit_limit\"),\n",
    "    F.col(\"has_chip\"),\n",
    "    F.col(\"dark_web_exposure\"),\n",
    "    \n",
    "    # Derived Feature\n",
    "    F.col(\"age_of_card_years\").alias(\"age_of_card\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ac251ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, lit, window, avg, sum, count, countDistinct, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "854f1fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 6: Creating Composite Features (Enrichment) ---\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`merchant_state`' given input columns: [yearly_income, num_credit_cards, financial_db.transactions_silver.transaction_timestamp, financial_db.cards_silver.year_pin_last_changed, financial_db.cards_silver.cards_issued, financial_db.cards_silver.credit_limit, financial_db.transactions_silver.year, financial_db.transactions_silver.user_id, acct_year, financial_db.cards_silver.card_brand, financial_db.cards_silver.card_number, financial_db.cards_silver.cvv, acct_month, dark_web_exposure, total_debt, financial_db.cards_silver.expires, per_capita_income, life_stage, financial_db.transactions_silver.card_id, state, time, city, financial_db.cards_silver.expires_year, day, credit_power, financial_db.transactions_silver.month, financial_db.cards_silver.card_type, debt_to_income_ratio, financial_db.cards_silver.expires_month, gender, age, financial_db.cards_silver.has_chip, fico_score];;\\n'Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 10 more fields]\\n+- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 9 more fields]\\n   +- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 8 more fields]\\n      +- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 7 more fields]\\n         +- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 6 more fields]\\n            +- Join LeftOuter, ((user_id#0 = user_id#497) && (card_id#1 = card_id#514))\\n               :- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, user_city#397 AS city#650, user_state#417 AS state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477]\\n               :  +- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, merchant_zip#276, mcc#8, transaction_errors#291, is_fraud#10, transaction_timestamp#11, year#12, month#13, day#306, time#322, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, ... 10 more fields]\\n               :     +- Join LeftOuter, (cast(user_id#0 as bigint) = user_id#339L)\\n               :        :- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, merchant_zip#276, mcc#8, transaction_errors#291, is_fraud#10, transaction_timestamp#11, year#12, month#13, day#306, date_format(transaction_timestamp#11, HH:mm:ss, Some(Asia/Kolkata)) AS time#322]\\n               :        :  +- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, merchant_zip#276, mcc#8, transaction_errors#291, is_fraud#10, transaction_timestamp#11, year#12, month#13, dayofmonth(cast(transaction_timestamp#11 as date)) AS day#306]\\n               :        :     +- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, merchant_zip#276, mcc#8, errors#9 AS transaction_errors#291, is_fraud#10, transaction_timestamp#11, year#12, month#13]\\n               :        :        +- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, zip#7 AS merchant_zip#276, mcc#8, errors#9, is_fraud#10, transaction_timestamp#11, year#12, month#13]\\n               :        :           +- SubqueryAlias `financial_db`.`transactions_silver`\\n               :        :              +- HiveTableRelation `financial_db`.`transactions_silver`, org.apache.hadoop.hive.ql.io.orc.OrcSerde, [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, zip#7, mcc#8, errors#9, is_fraud#10, transaction_timestamp#11], [year#12, month#13]\\n               :        +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, user_city#397, user_state#417, zipcode#350, latitude#351, longitude#352, per_capita_income#437, yearly_income#457, total_debt#355 AS total_debt#477, fico_score#356L, num_credit_cards#357L]\\n               :           +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, user_city#397, user_state#417, zipcode#350, latitude#351, longitude#352, per_capita_income#437, yearly_income_person#354 AS yearly_income#457, total_debt#355, fico_score#356L, num_credit_cards#357L]\\n               :              +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, user_city#397, user_state#417, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353 AS per_capita_income#437, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L]\\n               :                 +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, user_city#397, state#349 AS user_state#417, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L]\\n               :                    +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, city#348 AS user_city#397, state#349, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L]\\n               :                       +- Project [user_id#339L, person_id#340, current_age#341L AS age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, city#348, state#349, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L]\\n               :                          +- LogicalRDD [user_id#339L, person_id#340, current_age#341L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, city#348, state#349, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L], false\\n               +- Project [user_id#497, card_id#514, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, dark_web_exposure#531, acct_opened_month#76 AS acct_month#565, acct_year#548, expires_month#78, expires_year#79]\\n                  +- Project [user_id#497, card_id#514, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, dark_web_exposure#531, acct_opened_month#76, acct_opened_year#77 AS acct_year#548, expires_month#78, expires_year#79]\\n                     +- Project [user_id#497, card_id#514, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, card_on_dark_web#75 AS dark_web_exposure#531, acct_opened_month#76, acct_opened_year#77, expires_month#78, expires_year#79]\\n                        +- Project [user_id#497, card_index#65 AS card_id#514, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, card_on_dark_web#75, acct_opened_month#76, acct_opened_year#77, expires_month#78, expires_year#79]\\n                           +- Project [user#64 AS user_id#497, card_index#65, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, card_on_dark_web#75, acct_opened_month#76, acct_opened_year#77, expires_month#78, expires_year#79]\\n                              +- SubqueryAlias `financial_db`.`cards_silver`\\n                                 +- HiveTableRelation `financial_db`.`cards_silver`, org.apache.hadoop.hive.ql.io.orc.OrcSerde, [user#64, card_index#65, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, card_on_dark_web#75, acct_opened_month#76, acct_opened_year#77, expires_month#78, expires_year#79]\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o391.withColumn.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`merchant_state`' given input columns: [yearly_income, num_credit_cards, financial_db.transactions_silver.transaction_timestamp, financial_db.cards_silver.year_pin_last_changed, financial_db.cards_silver.cards_issued, financial_db.cards_silver.credit_limit, financial_db.transactions_silver.year, financial_db.transactions_silver.user_id, acct_year, financial_db.cards_silver.card_brand, financial_db.cards_silver.card_number, financial_db.cards_silver.cvv, acct_month, dark_web_exposure, total_debt, financial_db.cards_silver.expires, per_capita_income, life_stage, financial_db.transactions_silver.card_id, state, time, city, financial_db.cards_silver.expires_year, day, credit_power, financial_db.transactions_silver.month, financial_db.cards_silver.card_type, debt_to_income_ratio, financial_db.cards_silver.expires_month, gender, age, financial_db.cards_silver.has_chip, fico_score];;\n'Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 10 more fields]\n+- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 9 more fields]\n   +- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 8 more fields]\n      +- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 7 more fields]\n         +- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 6 more fields]\n            +- Join LeftOuter, ((user_id#0 = user_id#497) && (card_id#1 = card_id#514))\n               :- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, user_city#397 AS city#650, user_state#417 AS state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477]\n               :  +- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, merchant_zip#276, mcc#8, transaction_errors#291, is_fraud#10, transaction_timestamp#11, year#12, month#13, day#306, time#322, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, ... 10 more fields]\n               :     +- Join LeftOuter, (cast(user_id#0 as bigint) = user_id#339L)\n               :        :- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, merchant_zip#276, mcc#8, transaction_errors#291, is_fraud#10, transaction_timestamp#11, year#12, month#13, day#306, date_format(transaction_timestamp#11, HH:mm:ss, Some(Asia/Kolkata)) AS time#322]\n               :        :  +- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, merchant_zip#276, mcc#8, transaction_errors#291, is_fraud#10, transaction_timestamp#11, year#12, month#13, dayofmonth(cast(transaction_timestamp#11 as date)) AS day#306]\n               :        :     +- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, merchant_zip#276, mcc#8, errors#9 AS transaction_errors#291, is_fraud#10, transaction_timestamp#11, year#12, month#13]\n               :        :        +- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, zip#7 AS merchant_zip#276, mcc#8, errors#9, is_fraud#10, transaction_timestamp#11, year#12, month#13]\n               :        :           +- SubqueryAlias `financial_db`.`transactions_silver`\n               :        :              +- HiveTableRelation `financial_db`.`transactions_silver`, org.apache.hadoop.hive.ql.io.orc.OrcSerde, [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, zip#7, mcc#8, errors#9, is_fraud#10, transaction_timestamp#11], [year#12, month#13]\n               :        +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, user_city#397, user_state#417, zipcode#350, latitude#351, longitude#352, per_capita_income#437, yearly_income#457, total_debt#355 AS total_debt#477, fico_score#356L, num_credit_cards#357L]\n               :           +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, user_city#397, user_state#417, zipcode#350, latitude#351, longitude#352, per_capita_income#437, yearly_income_person#354 AS yearly_income#457, total_debt#355, fico_score#356L, num_credit_cards#357L]\n               :              +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, user_city#397, user_state#417, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353 AS per_capita_income#437, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L]\n               :                 +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, user_city#397, state#349 AS user_state#417, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L]\n               :                    +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, city#348 AS user_city#397, state#349, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L]\n               :                       +- Project [user_id#339L, person_id#340, current_age#341L AS age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, city#348, state#349, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L]\n               :                          +- LogicalRDD [user_id#339L, person_id#340, current_age#341L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, city#348, state#349, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L], false\n               +- Project [user_id#497, card_id#514, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, dark_web_exposure#531, acct_opened_month#76 AS acct_month#565, acct_year#548, expires_month#78, expires_year#79]\n                  +- Project [user_id#497, card_id#514, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, dark_web_exposure#531, acct_opened_month#76, acct_opened_year#77 AS acct_year#548, expires_month#78, expires_year#79]\n                     +- Project [user_id#497, card_id#514, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, card_on_dark_web#75 AS dark_web_exposure#531, acct_opened_month#76, acct_opened_year#77, expires_month#78, expires_year#79]\n                        +- Project [user_id#497, card_index#65 AS card_id#514, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, card_on_dark_web#75, acct_opened_month#76, acct_opened_year#77, expires_month#78, expires_year#79]\n                           +- Project [user#64 AS user_id#497, card_index#65, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, card_on_dark_web#75, acct_opened_month#76, acct_opened_year#77, expires_month#78, expires_year#79]\n                              +- SubqueryAlias `financial_db`.`cards_silver`\n                                 +- HiveTableRelation `financial_db`.`cards_silver`, org.apache.hadoop.hive.ql.io.orc.OrcSerde, [user#64, card_index#65, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, card_on_dark_web#75, acct_opened_month#76, acct_opened_year#77, expires_month#78, expires_year#79]\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:111)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:279)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$mapChild$2(TreeNode.scala:306)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4$$anonfun$apply$13.apply(TreeNode.scala:356)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:296)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:356)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:121)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:121)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3412)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1340)\n\tat org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2258)\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2225)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d2ba2ee36ccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"merchant_state\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user_state\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     ).otherwise(0)\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# D. Tech Complexity (Chip vs Online vs Swipe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   1995\u001b[0m         \"\"\"\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`merchant_state`' given input columns: [yearly_income, num_credit_cards, financial_db.transactions_silver.transaction_timestamp, financial_db.cards_silver.year_pin_last_changed, financial_db.cards_silver.cards_issued, financial_db.cards_silver.credit_limit, financial_db.transactions_silver.year, financial_db.transactions_silver.user_id, acct_year, financial_db.cards_silver.card_brand, financial_db.cards_silver.card_number, financial_db.cards_silver.cvv, acct_month, dark_web_exposure, total_debt, financial_db.cards_silver.expires, per_capita_income, life_stage, financial_db.transactions_silver.card_id, state, time, city, financial_db.cards_silver.expires_year, day, credit_power, financial_db.transactions_silver.month, financial_db.cards_silver.card_type, debt_to_income_ratio, financial_db.cards_silver.expires_month, gender, age, financial_db.cards_silver.has_chip, fico_score];;\\n'Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 10 more fields]\\n+- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 9 more fields]\\n   +- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 8 more fields]\\n      +- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 7 more fields]\\n         +- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, city#650, state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, ... 6 more fields]\\n            +- Join LeftOuter, ((user_id#0 = user_id#497) && (card_id#1 = card_id#514))\\n               :- Project [user_id#0, card_id#1, year#12, month#13, day#306, time#322, transaction_timestamp#11, age#377L, gender#345, user_city#397 AS city#650, user_state#417 AS state#651, per_capita_income#437, yearly_income#457, fico_score#356L, num_credit_cards#357L, total_debt#477]\\n               :  +- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, merchant_zip#276, mcc#8, transaction_errors#291, is_fraud#10, transaction_timestamp#11, year#12, month#13, day#306, time#322, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, ... 10 more fields]\\n               :     +- Join LeftOuter, (cast(user_id#0 as bigint) = user_id#339L)\\n               :        :- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, merchant_zip#276, mcc#8, transaction_errors#291, is_fraud#10, transaction_timestamp#11, year#12, month#13, day#306, date_format(transaction_timestamp#11, HH:mm:ss, Some(Asia/Kolkata)) AS time#322]\\n               :        :  +- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, merchant_zip#276, mcc#8, transaction_errors#291, is_fraud#10, transaction_timestamp#11, year#12, month#13, dayofmonth(cast(transaction_timestamp#11 as date)) AS day#306]\\n               :        :     +- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, merchant_zip#276, mcc#8, errors#9 AS transaction_errors#291, is_fraud#10, transaction_timestamp#11, year#12, month#13]\\n               :        :        +- Project [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, zip#7 AS merchant_zip#276, mcc#8, errors#9, is_fraud#10, transaction_timestamp#11, year#12, month#13]\\n               :        :           +- SubqueryAlias `financial_db`.`transactions_silver`\\n               :        :              +- HiveTableRelation `financial_db`.`transactions_silver`, org.apache.hadoop.hive.ql.io.orc.OrcSerde, [user_id#0, card_id#1, amount#2, use_chip#3, merchant_name#4, merchant_city#5, merchant_state#6, zip#7, mcc#8, errors#9, is_fraud#10, transaction_timestamp#11], [year#12, month#13]\\n               :        +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, user_city#397, user_state#417, zipcode#350, latitude#351, longitude#352, per_capita_income#437, yearly_income#457, total_debt#355 AS total_debt#477, fico_score#356L, num_credit_cards#357L]\\n               :           +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, user_city#397, user_state#417, zipcode#350, latitude#351, longitude#352, per_capita_income#437, yearly_income_person#354 AS yearly_income#457, total_debt#355, fico_score#356L, num_credit_cards#357L]\\n               :              +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, user_city#397, user_state#417, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353 AS per_capita_income#437, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L]\\n               :                 +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, user_city#397, state#349 AS user_state#417, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L]\\n               :                    +- Project [user_id#339L, person_id#340, age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, city#348 AS user_city#397, state#349, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L]\\n               :                       +- Project [user_id#339L, person_id#340, current_age#341L AS age#377L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, city#348, state#349, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L]\\n               :                          +- LogicalRDD [user_id#339L, person_id#340, current_age#341L, retirement_age#342L, birth_year#343L, birth_month#344L, gender#345, address#346, apartment#347, city#348, state#349, zipcode#350, latitude#351, longitude#352, per_capita_income_zipcode#353, yearly_income_person#354, total_debt#355, fico_score#356L, num_credit_cards#357L], false\\n               +- Project [user_id#497, card_id#514, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, dark_web_exposure#531, acct_opened_month#76 AS acct_month#565, acct_year#548, expires_month#78, expires_year#79]\\n                  +- Project [user_id#497, card_id#514, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, dark_web_exposure#531, acct_opened_month#76, acct_opened_year#77 AS acct_year#548, expires_month#78, expires_year#79]\\n                     +- Project [user_id#497, card_id#514, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, card_on_dark_web#75 AS dark_web_exposure#531, acct_opened_month#76, acct_opened_year#77, expires_month#78, expires_year#79]\\n                        +- Project [user_id#497, card_index#65 AS card_id#514, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, card_on_dark_web#75, acct_opened_month#76, acct_opened_year#77, expires_month#78, expires_year#79]\\n                           +- Project [user#64 AS user_id#497, card_index#65, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, card_on_dark_web#75, acct_opened_month#76, acct_opened_year#77, expires_month#78, expires_year#79]\\n                              +- SubqueryAlias `financial_db`.`cards_silver`\\n                                 +- HiveTableRelation `financial_db`.`cards_silver`, org.apache.hadoop.hive.ql.io.orc.OrcSerde, [user#64, card_index#65, card_brand#66, card_type#67, card_number#68, expires#69, cvv#70, has_chip#71, cards_issued#72, credit_limit#73, year_pin_last_changed#74, card_on_dark_web#75, acct_opened_month#76, acct_opened_year#77, expires_month#78, expires_year#79]\\n\""
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. Advanced Feature Engineering\n",
    "# ==========================================\n",
    "print(\"--- Step 6: Creating Composite Features (Enrichment) ---\")\n",
    "\n",
    "# We work on df_join_cards because we need the raw columns (amount, timestamp, etc.)\n",
    "# which might have been dropped in the previous selection step.\n",
    "\n",
    "df_enriched = df_join_cards.withColumn(\n",
    "    # A. Financial Ratios\n",
    "    \"debt_to_income_ratio\",\n",
    "    when(col(\"yearly_income\") > 0, \n",
    "         col(\"total_debt\") / col(\"yearly_income\")\n",
    "    ).otherwise(0.0)\n",
    ").withColumn(\n",
    "    \"credit_power\",\n",
    "    when(col(\"yearly_income\") > 0, \n",
    "         col(\"credit_limit\") / col(\"yearly_income\")\n",
    "    ).otherwise(0.0)\n",
    ").withColumn(\n",
    "    # B. Demographic Segmentation (Life Stage)\n",
    "    \"life_stage\",\n",
    "    when(col(\"age\") < 30, \"Young_Adult\")\n",
    "    .when((col(\"age\") >= 30) & (col(\"age\") < 60), \"Working_Professional\")\n",
    "    .otherwise(\"Retired\")\n",
    ").withColumn(\n",
    "    # C. Traveller Flag (User State != Merchant State)\n",
    "    # Important: Handle nulls for Online transactions\n",
    "    \"is_travelling\",\n",
    "    when(\n",
    "        (col(\"merchant_state\").isNotNull()) & \n",
    "        (col(\"user_state\").isNotNull()) & \n",
    "        (col(\"merchant_state\") != col(\"user_state\")), \n",
    "        1\n",
    "    ).otherwise(0)\n",
    ").withColumn(\n",
    "    # D. Tech Complexity (Chip vs Online vs Swipe)\n",
    "    \"tech_type\",\n",
    "    when(col(\"use_chip\").like(\"%Chip%\"), \"Chip\")\n",
    "    .when(col(\"use_chip\").like(\"%Online%\"), \"Online\")\n",
    "    .otherwise(\"Swipe\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f20b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========================================\n",
    "# 7. Aggregation (The Golden Layer Logic)\n",
    "# ==========================================\n",
    "print(\"--- Step 7: Aggregating into 15-Minute Windows ---\")\n",
    "\n",
    "df_gold_mart = df_enriched.groupBy(\n",
    "    window(col(\"transaction_timestamp\"), \"15 minutes\")\n",
    ").agg(\n",
    "    # --- 1. Core Forecasting Metrics (Target Variables) ---\n",
    "    count(\"*\").alias(\"transaction_count\"),      # Load (TPS)\n",
    "    sum(\"amount\").alias(\"total_volume\"),        # Liability ($)\n",
    "    avg(\"amount\").alias(\"avg_transaction_size\"),\n",
    "    \n",
    "    # --- 2. System Health Metrics ---\n",
    "    # Adjust 'errors' column name if it was renamed to 'transaction_errors' earlier\n",
    "    count(when(col(\"transaction_errors\") != \"N/A\", 1)).alias(\"error_count\"),\n",
    "    count(when(col(\"is_fraud\") == \"Yes\", 1)).alias(\"fraud_count\"),\n",
    "    \n",
    "    # --- 3. Enriched Behavioral Metrics (NEW) ---\n",
    "    # These help the model understand WHY load is happening\n",
    "    \n",
    "    # Financial Health of current traffic\n",
    "    avg(\"debt_to_income_ratio\").alias(\"avg_debt_ratio\"),\n",
    "    avg(\"credit_power\").alias(\"avg_credit_power\"),\n",
    "    \n",
    "    # Traveller Traffic (Spikes during holidays)\n",
    "    sum(\"is_travelling\").alias(\"traveller_count\"),\n",
    "    \n",
    "    # Life Stage Breakdown (Pivot Logic)\n",
    "    # Count how many of each group are active in this window\n",
    "    count(when(col(\"life_stage\") == \"Young_Adult\", 1)).alias(\"cnt_young_adult\"),\n",
    "    count(when(col(\"life_stage\") == \"Working_Professional\", 1)).alias(\"cnt_professional\"),\n",
    "    count(when(col(\"life_stage\") == \"Retired\", 1)).alias(\"cnt_retired\"),\n",
    "    \n",
    "    # Tech Type Breakdown\n",
    "    count(when(col(\"tech_type\") == \"Chip\", 1)).alias(\"cnt_chip\"),\n",
    "    count(when(col(\"tech_type\") == \"Online\", 1)).alias(\"cnt_online\"),\n",
    "    count(when(col(\"tech_type\") == \"Swipe\", 1)).alias(\"cnt_swipe\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 8. Final Formatting & Save\n",
    "# ==========================================\n",
    "print(\"--- Step 8: Formatting & Saving Data Mart ---\")\n",
    "\n",
    "# Extract 'ds' timestamp for Prophet and clean up schema\n",
    "df_final_gold = df_gold_mart.withColumn(\n",
    "    \"ds\", \n",
    "    col(\"window.start\")\n",
    ").select(\n",
    "    \"ds\",\n",
    "    # Targets\n",
    "    col(\"transaction_count\").cast(\"long\"),\n",
    "    col(\"total_volume\").cast(\"decimal(18,2)\"),\n",
    "    col(\"avg_transaction_size\").cast(\"decimal(10,2)\"),\n",
    "    \n",
    "    # Health\n",
    "    col(\"error_count\").cast(\"long\"),\n",
    "    col(\"fraud_count\").cast(\"long\"),\n",
    "    \n",
    "    # Features\n",
    "    col(\"avg_debt_ratio\").cast(\"decimal(10,4)\"),\n",
    "    col(\"traveller_count\").cast(\"long\"),\n",
    "    col(\"cnt_young_adult\").cast(\"long\"),\n",
    "    col(\"cnt_professional\").cast(\"long\"),\n",
    "    col(\"cnt_retired\").cast(\"long\"),\n",
    "    col(\"cnt_online\").cast(\"long\"),\n",
    "    col(\"cnt_chip\").cast(\"long\")\n",
    ").fillna(0) # Impute Nulls with 0 for clean Time Series\n",
    "\n",
    "# Preview\n",
    "df_final_gold.orderBy(\"ds\").show(10, truncate=False)\n",
    "df_final_gold.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f811a881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 6: Final Data Mart Preview ---\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- card_id: integer (nullable = true)\n",
      " |-- user_age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- per_capita_income: decimal(38,18) (nullable = true)\n",
      " |-- yearly_income: decimal(38,18) (nullable = true)\n",
      " |-- fico_score: long (nullable = true)\n",
      " |-- num_credit_cards: long (nullable = true)\n",
      " |-- total_debt: decimal(38,18) (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- credit_limit: decimal(10,2) (nullable = true)\n",
      " |-- has_chip: string (nullable = true)\n",
      " |-- dark_web_exposure: string (nullable = true)\n",
      " |-- age_of_card: integer (nullable = true)\n",
      "\n",
      "+-------+-------+--------+------+-----------+-----+--------------------+--------------------+----------+----------------+--------------------+----+-----+---+--------+---------+------------+--------+-----------------+-----------+\n",
      "|user_id|card_id|user_age|gender|       city|state|   per_capita_income|       yearly_income|fico_score|num_credit_cards|          total_debt|year|month|day|    time|card_type|credit_limit|has_chip|dark_web_exposure|age_of_card|\n",
      "+-------+-------+--------+------+-----------+-----+--------------------+--------------------+----------+----------------+--------------------+----+-----+---+--------+---------+------------+--------+-----------------+-----------+\n",
      "|    196|      0|      37|Female|Minneapolis|   MN|22059.00000000000...|44976.00000000000...|       684|               1|134335.0000000000...|2009|    3|  1|12:44:00|    Debit|    18937.00|     YES|               No|          4|\n",
      "|    196|      0|      37|Female|Minneapolis|   MN|22059.00000000000...|44976.00000000000...|       684|               1|134335.0000000000...|2009|    3|  1|13:28:00|    Debit|    18937.00|     YES|               No|          4|\n",
      "|    196|      0|      37|Female|Minneapolis|   MN|22059.00000000000...|44976.00000000000...|       684|               1|134335.0000000000...|2009|    3|  1|17:15:00|    Debit|    18937.00|     YES|               No|          4|\n",
      "|    196|      0|      37|Female|Minneapolis|   MN|22059.00000000000...|44976.00000000000...|       684|               1|134335.0000000000...|2009|    3|  2|05:03:00|    Debit|    18937.00|     YES|               No|          4|\n",
      "|    196|      0|      37|Female|Minneapolis|   MN|22059.00000000000...|44976.00000000000...|       684|               1|134335.0000000000...|2009|    3|  2|13:21:00|    Debit|    18937.00|     YES|               No|          4|\n",
      "|    196|      0|      37|Female|Minneapolis|   MN|22059.00000000000...|44976.00000000000...|       684|               1|134335.0000000000...|2009|    3|  3|14:15:00|    Debit|    18937.00|     YES|               No|          4|\n",
      "|    196|      0|      37|Female|Minneapolis|   MN|22059.00000000000...|44976.00000000000...|       684|               1|134335.0000000000...|2009|    3|  4|13:25:00|    Debit|    18937.00|     YES|               No|          4|\n",
      "|    196|      0|      37|Female|Minneapolis|   MN|22059.00000000000...|44976.00000000000...|       684|               1|134335.0000000000...|2009|    3|  5|13:25:00|    Debit|    18937.00|     YES|               No|          4|\n",
      "|    196|      0|      37|Female|Minneapolis|   MN|22059.00000000000...|44976.00000000000...|       684|               1|134335.0000000000...|2009|    3|  5|19:57:00|    Debit|    18937.00|     YES|               No|          4|\n",
      "|    196|      0|      37|Female|Minneapolis|   MN|22059.00000000000...|44976.00000000000...|       684|               1|134335.0000000000...|2009|    3|  6|13:13:00|    Debit|    18937.00|     YES|               No|          4|\n",
      "+-------+-------+--------+------+-----------+-----+--------------------+--------------------+----------+----------------+--------------------+----+-----+---+--------+---------+------------+--------+-----------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. Preview Output\n",
    "# ==========================================\n",
    "print(\"--- Step 6: Final Data Mart Preview ---\")\n",
    "df_final.printSchema()\n",
    "df_final.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f07633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64920d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa1396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06cbe655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 6: Saving as External Hive Table ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Step 6: Saving as External Hive Table ---\")\n",
    "# Path for the External Table\n",
    "gold_path = \"/user/talentum/projectMaster/warehouseDir/gold/financial_load_forecasting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark.conf.set(\"spark.sql.orc.enableVectorizedReader\", \"false\")\n",
    "spark.conf.set(\"spark.sql.hive.convertMetastoreOrc\", \"false\")\n",
    "\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
