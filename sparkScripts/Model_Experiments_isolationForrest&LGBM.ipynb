{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de291f1-1b88-449c-9b4b-4a01023819ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.orc as orc\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, average_precision_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15032e3c-2d7b-4ba4-83e0-9b7bef63eab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 16,000,000 rows.\n",
      "    transaction_id  user_id  card           merchant_id  label_is_fraud  \\\n",
      "0  61-5-1514771820       61     5   1799189980464955940               0   \n",
      "1  61-5-1514894100       61     5  -4169251800658106093               0   \n",
      "2  61-5-1515899580       61     5  -4752064311331295725               0   \n",
      "3  61-5-1516172520       61     5   6455213054093379528               0   \n",
      "4  61-5-1516275060       61     5  -4169251800658106093               0   \n",
      "\n",
      "  amount  hour_of_day use_chip  merchant_category error_code  \\\n",
      "0   6.39            7     Chip               5499        N/A   \n",
      "1  29.11           17     Chip               5812        N/A   \n",
      "2  14.90            8     Chip               4214        N/A   \n",
      "3  18.77           12   Online               5815        N/A   \n",
      "4  34.77           17     Chip               5812        N/A   \n",
      "\n",
      "   credit_utilization  state_mismatch  current_age yearly_income_person  \\\n",
      "0            0.000215               0           63             56635.00   \n",
      "1            0.000979               0           63             56635.00   \n",
      "2            0.000501               0           63             56635.00   \n",
      "3            0.000631               0           63             56635.00   \n",
      "4            0.001169               0           63             56635.00   \n",
      "\n",
      "   fico_score card_type card_brand  \n",
      "0         786     Debit       Visa  \n",
      "1         786     Debit       Visa  \n",
      "2         786     Debit       Visa  \n",
      "3         786     Debit       Visa  \n",
      "4         786     Debit       Visa  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000000 entries, 0 to 15999999\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   transaction_id        object \n",
      " 1   user_id               int32  \n",
      " 2   card                  int32  \n",
      " 3   merchant_id           object \n",
      " 4   label_is_fraud        int32  \n",
      " 5   amount                object \n",
      " 6   hour_of_day           int32  \n",
      " 7   use_chip              object \n",
      " 8   merchant_category     int32  \n",
      " 9   error_code            object \n",
      " 10  credit_utilization    float64\n",
      " 11  state_mismatch        int32  \n",
      " 12  current_age           int32  \n",
      " 13  yearly_income_person  object \n",
      " 14  fico_score            int32  \n",
      " 15  card_type             object \n",
      " 16  card_brand            object \n",
      "dtypes: float64(1), int32(8), object(8)\n",
      "memory usage: 1.5+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the file path\n",
    "path = r'C:/BigData/ProjectStaging/dataExport/fraud_mart_final.orc'\n",
    "\n",
    "# 2. Load the file using PyArrow\n",
    "orc_file = orc.ORCFile(path)\n",
    "\n",
    "# 3. Read the table and slice it immediately to 16M rows\n",
    "# table.slice(offset, length) is memory efficient\n",
    "table = orc_file.read().slice(0, 16000000)\n",
    "\n",
    "# 4. Convert to Pandas with \"self_destruct\" to keep memory footprint low\n",
    "# self_destruct=True: Frees the Arrow memory AS it creates the Pandas DF\n",
    "# split_blocks=True: Prevents needing one single massive contiguous block of RAM\n",
    "df = table.to_pandas(split_blocks=True, self_destruct=True)\n",
    "\n",
    "print(f\"Successfully loaded {len(df):,} rows.\")\n",
    "print(df.head())\n",
    "print(df.info()) # Check memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f7a942-e893-40f4-8e54-8f9f08fa85a2",
   "metadata": {},
   "source": [
    "### TIME EXTRACTION & SORTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50eebfc2-8a7d-4a6e-8b74-6948294ba095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: extracting timestamps and sorting...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>card</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label_is_fraud</th>\n",
       "      <th>amount</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>use_chip</th>\n",
       "      <th>merchant_category</th>\n",
       "      <th>error_code</th>\n",
       "      <th>credit_utilization</th>\n",
       "      <th>state_mismatch</th>\n",
       "      <th>current_age</th>\n",
       "      <th>yearly_income_person</th>\n",
       "      <th>fico_score</th>\n",
       "      <th>card_type</th>\n",
       "      <th>card_brand</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>791-1-662780400</td>\n",
       "      <td>791</td>\n",
       "      <td>1</td>\n",
       "      <td>2027553650310142703</td>\n",
       "      <td>0</td>\n",
       "      <td>68.00</td>\n",
       "      <td>7</td>\n",
       "      <td>Swipe</td>\n",
       "      <td>5541</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>72510.00</td>\n",
       "      <td>727</td>\n",
       "      <td>Credit</td>\n",
       "      <td>Amex</td>\n",
       "      <td>662780400</td>\n",
       "      <td>1991-01-02 01:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>791-1-662780820</td>\n",
       "      <td>791</td>\n",
       "      <td>1</td>\n",
       "      <td>2027553650310142703</td>\n",
       "      <td>0</td>\n",
       "      <td>-68.00</td>\n",
       "      <td>7</td>\n",
       "      <td>Swipe</td>\n",
       "      <td>5541</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.002006</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>72510.00</td>\n",
       "      <td>727</td>\n",
       "      <td>Credit</td>\n",
       "      <td>Amex</td>\n",
       "      <td>662780820</td>\n",
       "      <td>1991-01-02 01:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>791-1-662781060</td>\n",
       "      <td>791</td>\n",
       "      <td>1</td>\n",
       "      <td>2027553650310142703</td>\n",
       "      <td>0</td>\n",
       "      <td>113.62</td>\n",
       "      <td>7</td>\n",
       "      <td>Swipe</td>\n",
       "      <td>5541</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>72510.00</td>\n",
       "      <td>727</td>\n",
       "      <td>Credit</td>\n",
       "      <td>Amex</td>\n",
       "      <td>662781060</td>\n",
       "      <td>1991-01-02 01:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>791-1-662817600</td>\n",
       "      <td>791</td>\n",
       "      <td>1</td>\n",
       "      <td>-7269691894846892021</td>\n",
       "      <td>0</td>\n",
       "      <td>114.73</td>\n",
       "      <td>17</td>\n",
       "      <td>Swipe</td>\n",
       "      <td>5411</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>72510.00</td>\n",
       "      <td>727</td>\n",
       "      <td>Credit</td>\n",
       "      <td>Amex</td>\n",
       "      <td>662817600</td>\n",
       "      <td>1991-01-02 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>791-1-662873580</td>\n",
       "      <td>791</td>\n",
       "      <td>1</td>\n",
       "      <td>-3693650930986299431</td>\n",
       "      <td>0</td>\n",
       "      <td>251.71</td>\n",
       "      <td>9</td>\n",
       "      <td>Swipe</td>\n",
       "      <td>4814</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>72510.00</td>\n",
       "      <td>727</td>\n",
       "      <td>Credit</td>\n",
       "      <td>Amex</td>\n",
       "      <td>662873580</td>\n",
       "      <td>1991-01-03 03:33:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    transaction_id  user_id  card           merchant_id  label_is_fraud  \\\n",
       "0  791-1-662780400      791     1   2027553650310142703               0   \n",
       "1  791-1-662780820      791     1   2027553650310142703               0   \n",
       "2  791-1-662781060      791     1   2027553650310142703               0   \n",
       "3  791-1-662817600      791     1  -7269691894846892021               0   \n",
       "4  791-1-662873580      791     1  -3693650930986299431               0   \n",
       "\n",
       "   amount  hour_of_day use_chip  merchant_category error_code  \\\n",
       "0   68.00            7    Swipe               5541        N/A   \n",
       "1  -68.00            7    Swipe               5541        N/A   \n",
       "2  113.62            7    Swipe               5541        N/A   \n",
       "3  114.73           17    Swipe               5411        N/A   \n",
       "4  251.71            9    Swipe               4814        N/A   \n",
       "\n",
       "   credit_utilization  state_mismatch  current_age yearly_income_person  \\\n",
       "0            0.002006               0           58             72510.00   \n",
       "1           -0.002006               0           58             72510.00   \n",
       "2            0.003352               0           58             72510.00   \n",
       "3            0.003384               0           58             72510.00   \n",
       "4            0.007425               0           58             72510.00   \n",
       "\n",
       "   fico_score card_type card_brand  unix_time            datetime  \n",
       "0         727    Credit       Amex  662780400 1991-01-02 01:40:00  \n",
       "1         727    Credit       Amex  662780820 1991-01-02 01:47:00  \n",
       "2         727    Credit       Amex  662781060 1991-01-02 01:51:00  \n",
       "3         727    Credit       Amex  662817600 1991-01-02 12:00:00  \n",
       "4         727    Credit       Amex  662873580 1991-01-03 03:33:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Step 1: extracting timestamps and sorting...\")\n",
    "\n",
    "import gc\n",
    "\n",
    "# 1. Extract Unix Timestamp from transaction_id (Format: User-Card-Timestamp)\n",
    "# taking the last part of the string '61-5-1514771820' -> '1514771820'\n",
    "df['unix_time'] = df['transaction_id'].str.split('-').str[-1].astype(int)\n",
    "\n",
    "# 2. Convert to Datetime object\n",
    "df['datetime'] = pd.to_datetime(df['unix_time'], unit='s')\n",
    "\n",
    "# 3. Sort by Time (Oldest -> Newest) to respect Time Series nature\n",
    "df.sort_values('datetime', inplace = True)\n",
    "\n",
    "# 4. Reset index IN-PLACE\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb06e50-25e0-4aeb-9eea-1cf2def105ce",
   "metadata": {},
   "source": [
    "### FEATURE ENGINEERING (Time-Aware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c06599-07b3-478e-b169-c311554cce98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Memory-Surgical Feature Engineering...\n",
      "Calculating Velocity (trans_last_24h) using NumPy...\n",
      "Calculating user behavioral stats...\n",
      "Step 2 Finished successfully with zero memory leaks.\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 2: Memory-Surgical Feature Engineering...\")\n",
    "\n",
    "# 1. Convert Decimal 'amount' to float32 immediately\n",
    "df['amount'] = pd.to_numeric(df['amount'], errors='coerce').astype(np.float32)\n",
    "\n",
    "# 2. Convert Objects (Strings) to Categories\n",
    "for col in ['use_chip', 'card_type', 'error_code', 'merchant_category']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "# 3. Extract Time Components & Cyclical Encoding\n",
    "df['hour_of_day'] = df['datetime'].dt.hour.astype(np.int8)\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek.astype(np.int8)\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour_of_day'] / 24).astype(np.float32)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour_of_day'] / 24).astype(np.float32)\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7).astype(np.float32)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7).astype(np.float32)\n",
    "df.drop(columns=['hour_of_day', 'day_of_week'], inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "# 4. FIXED: Memory-Surgical 'trans_last_24h' (Velocity)\n",
    "print(\"Calculating Velocity (trans_last_24h) using NumPy...\")\n",
    "df.sort_values(['user_id', 'unix_time'], inplace=True)\n",
    "\n",
    "user_ids = df['user_id'].values\n",
    "unix_times = df['unix_time'].values\n",
    "velocity_counts = np.zeros(len(df), dtype=np.int16)\n",
    "\n",
    "# Find where each user's data starts and ends\n",
    "user_changes = np.where(user_ids[:-1] != user_ids[1:])[0] + 1\n",
    "user_starts = np.insert(user_changes, 0, 0)\n",
    "user_ends = np.append(user_changes, len(df))\n",
    "\n",
    "# Loop over each user (Efficient because it doesn't copy the DF)\n",
    "for start, end in zip(user_starts, user_ends):\n",
    "    user_time_window = unix_times[start:end]\n",
    "    # For every transaction, find how many happened in the previous 86400 seconds\n",
    "    # searchsorted is extremely fast (logarithmic time)\n",
    "    lookback_indices = np.searchsorted(user_time_window, user_time_window - 86400, side='left')\n",
    "    velocity_counts[start:end] = (np.arange(len(user_time_window)) - lookback_indices + 1).astype(np.int16)\n",
    "\n",
    "df['trans_last_24h'] = velocity_counts\n",
    "del user_ids, unix_times, velocity_counts, user_starts, user_ends, user_changes\n",
    "gc.collect()\n",
    "\n",
    "# 5. Time Since Last Transaction (Speed)\n",
    "df['time_since_last_trans'] = df['unix_time'].diff().fillna(0).astype(np.float32)\n",
    "user_changed = df['user_id'] != df['user_id'].shift(1)\n",
    "df.loc[user_changed, 'time_since_last_trans'] = 0\n",
    "del user_changed\n",
    "gc.collect()\n",
    "\n",
    "# 6. Amount Behavioral Features\n",
    "print(\"Calculating user behavioral stats...\")\n",
    "user_medians = df.groupby('user_id')['amount'].transform('median').astype(np.float32)\n",
    "df['diff_from_median'] = (df['amount'] - user_medians).astype(np.float32)\n",
    "df['amount_ratio'] = (df['amount'] / (user_medians + 1)).astype(np.float32)\n",
    "del user_medians\n",
    "gc.collect()\n",
    "\n",
    "# 7. Final Projection to save memory\n",
    "cols_to_keep = [\n",
    "    'amount', 'credit_utilization', 'current_age', 'yearly_income_person', \n",
    "    'fico_score', 'state_mismatch', 'time_since_last_trans', 'hour_sin', \n",
    "    'hour_cos', 'day_sin', 'day_cos', 'diff_from_median', 'amount_ratio',\n",
    "    'trans_last_24h', 'use_chip', 'card_type', 'error_code', 'merchant_category', \n",
    "    'label_is_fraud', 'unix_time'\n",
    "]\n",
    "df = df[cols_to_keep]\n",
    "gc.collect()\n",
    "\n",
    "print(\"Step 2 Finished successfully with zero memory leaks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea21691-a070-486e-bf5a-a7fad753455f",
   "metadata": {},
   "source": [
    "### Temporal Splitting and Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c75601b-99e9-44a6-9182-a2924a6f545c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Preparing Data for Splitting...\n",
      "--- Temporal Split Verification ---\n",
      "Train Period: 1991-01-02 01:40:00 to 2017-04-17 04:45:00\n",
      "Val   Period: 2017-04-17 04:46:00 to 2018-09-26 14:24:00\n",
      "Test  Period: 2018-09-26 14:24:00 to 2020-02-28 18:28:00\n",
      "\n",
      "Target encoding merchant_category...\n",
      "\n",
      "Step 3 Complete. Train, Val, and Test sets are ready.\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 3: Preparing Data for Splitting...\")\n",
    "\n",
    "# 1. Recover 'datetime' if it was dropped during memory optimization\n",
    "if 'datetime' not in df.columns and 'unix_time' in df.columns:\n",
    "    df['datetime'] = pd.to_datetime(df['unix_time'], unit='s')\n",
    "\n",
    "# 2. Global Temporal Sort (Ensures Test = Future transactions)\n",
    "# We sort by unix_time as it's faster than sorting by datetime objects\n",
    "df.sort_values('unix_time', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 3. Define Temporal Split (80% Train, 10% Val, 10% Test)\n",
    "train_size = int(len(df) * 0.8)\n",
    "val_size = int(len(df) * 0.1)\n",
    "\n",
    "train_df = df.iloc[:train_size].copy()\n",
    "val_df = df.iloc[train_size:train_size + val_size].copy()\n",
    "test_df = df.iloc[train_size + val_size:].copy()\n",
    "\n",
    "# Print timing info to verify the split is chronological\n",
    "print(f\"--- Temporal Split Verification ---\")\n",
    "print(f\"Train Period: {train_df['datetime'].min()} to {train_df['datetime'].max()}\")\n",
    "print(f\"Val   Period: {val_df['datetime'].min()} to {val_df['datetime'].max()}\")\n",
    "print(f\"Test  Period: {test_df['datetime'].min()} to {test_df['datetime'].max()}\")\n",
    "\n",
    "# 4. Target Encoding for Merchant Category (Crucial: Use ONLY Training labels)\n",
    "print(\"\\nTarget encoding merchant_category...\")\n",
    "mcc_map = train_df.groupby('merchant_category')['label_is_fraud'].mean()\n",
    "global_mean = train_df['label_is_fraud'].mean()\n",
    "\n",
    "# Map the fraud risk scores and convert to float32 for memory efficiency\n",
    "for d in [train_df, val_df, test_df]:\n",
    "    d['mcc_risk'] = d['merchant_category'].map(mcc_map).fillna(global_mean).astype(np.float32)\n",
    "\n",
    "# 5. Feature Selection\n",
    "numeric_features = [\n",
    "    'amount', 'credit_utilization', 'current_age', 'yearly_income_person', \n",
    "    'fico_score', 'trans_last_24h', 'amount_ratio', 'state_mismatch',\n",
    "    'time_since_last_trans', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos',\n",
    "    'mcc_risk', 'diff_from_median'\n",
    "]\n",
    "categorical_features = ['use_chip', 'card_type', 'error_code']\n",
    "\n",
    "X_train = train_df[numeric_features + categorical_features]\n",
    "y_train = train_df['label_is_fraud']\n",
    "\n",
    "X_val = val_df[numeric_features + categorical_features]\n",
    "y_val = val_df['label_is_fraud']\n",
    "\n",
    "X_test = test_df[numeric_features + categorical_features]\n",
    "y_test = test_df['label_is_fraud']\n",
    "\n",
    "# 6. Final Memory Clean up: Delete the original massive dataframe\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\nStep 3 Complete. Train, Val, and Test sets are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3682ff1-b93a-42cb-9e2a-63ee31e54a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature Engineering Updates Complete.\n",
      "Added/Verified: log_amount, log_time_gap, ['trans_last_24h', 'amount_ratio', 'diff_from_median', 'time_since_last_trans']\n"
     ]
    }
   ],
   "source": [
    "velocity_cols = ['trans_last_24h', 'amount_ratio', 'diff_from_median', 'time_since_last_trans']\n",
    "\n",
    "# B. Log-Transformation (For Skewed Amounts)\n",
    "# Paper mentions: \"Time gap patterns (log-transformed)\" and \"Amount statistics\"\n",
    "# Fraud amounts often follow a power law. Log helps linear models (like MLP).\n",
    "if 'amount' in X_train.columns:\n",
    "    X_train['log_amount'] = np.log1p(X_train['amount'])\n",
    "    X_val['log_amount'] = np.log1p(X_val['amount'])\n",
    "    X_test['log_amount'] = np.log1p(X_test['amount'])\n",
    "\n",
    "if 'time_since_last_trans' in X_train.columns:\n",
    "    X_train['log_time_gap'] = np.log1p(X_train['time_since_last_trans'])\n",
    "    X_val['log_time_gap'] = np.log1p(X_val['time_since_last_trans'])\n",
    "    X_test['log_time_gap'] = np.log1p(X_test['time_since_last_trans'])\n",
    "\n",
    "print(\"✅ Feature Engineering Updates Complete.\")\n",
    "print(f\"Added/Verified: log_amount, log_time_gap, {velocity_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c277fdf9-2133-4800-a18b-f53a157bfcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check dtypes - All should now be int or float:\n",
      "use_chip                  int32\n",
      "card_type                 int32\n",
      "error_code                int32\n",
      "yearly_income_person    float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Robustly convert all features to numeric for LGBM\n",
    "for d in [X_train, X_val, X_test]:\n",
    "    # 1. Fix 'yearly_income_person' (Object -> Float)\n",
    "    if 'yearly_income_person' in d.columns:\n",
    "        d['yearly_income_person'] = pd.to_numeric(d['yearly_income_person'], errors='coerce').astype(np.float32)\n",
    "    \n",
    "    # 2. Fix Categorical Features (Object/Category -> Integer Codes)\n",
    "    for col in categorical_features:\n",
    "        if col in d.columns:\n",
    "            # Explicitly cast to category first to avoid AttributeError, then get codes\n",
    "            d[col] = d[col].astype('category').cat.codes.astype(np.int32)\n",
    "\n",
    "print(\"Check dtypes - All should now be int or float:\")\n",
    "print(X_train[categorical_features + ['yearly_income_person']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0585e2bf-f253-45f0-93ed-f233bf743bbc",
   "metadata": {},
   "source": [
    "### Training a Isolation forest to attach a suspision score to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11c0e6f5-4a48-49d1-b94e-516e6dbdb83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Optimizing Isolation Forest Feature ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-24 18:20:20,181] A new study created in memory with name: no-name-967a67a4-eb1e-472f-b754-8c00877d4763\n",
      "[I 2026-01-24 18:20:25,475] Trial 0 finished with value: 0.2723966223791667 and parameters: {'n_estimators': 177, 'max_samples': 0.2682080272012195, 'max_features': 0.793422213713043}. Best is trial 0 with value: 0.2723966223791667.\n",
      "[I 2026-01-24 18:20:30,755] Trial 1 finished with value: 0.2828774986283914 and parameters: {'n_estimators': 161, 'max_samples': 0.5717853555135887, 'max_features': 0.5170548466964386}. Best is trial 1 with value: 0.2828774986283914.\n",
      "[I 2026-01-24 18:20:33,424] Trial 2 finished with value: 0.27019541212589593 and parameters: {'n_estimators': 73, 'max_samples': 0.850056624746398, 'max_features': 0.7841032548532858}. Best is trial 1 with value: 0.2828774986283914.\n",
      "[I 2026-01-24 18:20:36,824] Trial 3 finished with value: 0.2983559362192202 and parameters: {'n_estimators': 109, 'max_samples': 0.528452868285265, 'max_features': 0.5859198817873834}. Best is trial 3 with value: 0.2983559362192202.\n",
      "[I 2026-01-24 18:20:41,677] Trial 4 finished with value: 0.2727086639923642 and parameters: {'n_estimators': 121, 'max_samples': 0.9756011197374989, 'max_features': 0.906461624408752}. Best is trial 3 with value: 0.2983559362192202.\n",
      "[I 2026-01-24 18:20:43,563] Trial 5 finished with value: 0.2498390455661442 and parameters: {'n_estimators': 50, 'max_samples': 0.9331826942889052, 'max_features': 0.827822845814763}. Best is trial 3 with value: 0.2983559362192202.\n",
      "[I 2026-01-24 18:20:49,381] Trial 6 finished with value: 0.2811997435983899 and parameters: {'n_estimators': 170, 'max_samples': 0.9227151012725755, 'max_features': 0.5536935728370926}. Best is trial 3 with value: 0.2983559362192202.\n",
      "[I 2026-01-24 18:20:55,408] Trial 7 finished with value: 0.2749509201446425 and parameters: {'n_estimators': 170, 'max_samples': 0.6548607871423494, 'max_features': 0.9721977142547276}. Best is trial 3 with value: 0.2983559362192202.\n",
      "[I 2026-01-24 18:20:57,674] Trial 8 finished with value: 0.2752813572629913 and parameters: {'n_estimators': 68, 'max_samples': 0.29778954535928964, 'max_features': 0.8803561962820288}. Best is trial 3 with value: 0.2983559362192202.\n",
      "[I 2026-01-24 18:21:02,753] Trial 9 finished with value: 0.28504359076707403 and parameters: {'n_estimators': 178, 'max_samples': 0.14248127747860442, 'max_features': 0.6147206239293328}. Best is trial 3 with value: 0.2983559362192202.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IF Params: {'n_estimators': 109, 'max_samples': 0.528452868285265, 'max_features': 0.5859198817873834}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "\n",
    "print(\"--- Optimizing Isolation Forest Feature ---\")\n",
    "\n",
    "# 1. Create a manageable subsample for Optuna\n",
    "# IF is slow. We optimize on 100k rows to be fast.\n",
    "# We include ALL fraud in this sample to ensure the metric is valid.\n",
    "X_opt_fraud = X_train[y_train == 1]\n",
    "X_opt_normal = X_train[y_train == 0].sample(n=100000, random_state=42)\n",
    "X_opt = pd.concat([X_opt_fraud, X_opt_normal])\n",
    "y_opt = pd.concat([y_train[X_opt_fraud.index], y_train[X_opt_normal.index]])\n",
    "\n",
    "def objective_iso(trial):\n",
    "    # Search Space\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "    max_samples = trial.suggest_float('max_samples', 0.1, 1.0)\n",
    "    max_features = trial.suggest_float('max_features', 0.5, 1.0)\n",
    "    \n",
    "    # Train Model\n",
    "    clf = IsolationForest(\n",
    "        n_estimators=n_estimators,\n",
    "        max_samples=max_samples,\n",
    "        max_features=max_features,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_opt)\n",
    "    \n",
    "    # Predict (Lower score = More Anomalous)\n",
    "    # We invert the score (-) so that Higher = More Suspicious for AUC calculation\n",
    "    scores = -clf.decision_function(X_opt)\n",
    "    \n",
    "    # Maximize correlation with actual fraud\n",
    "    auc = average_precision_score(y_opt, scores)\n",
    "    return auc\n",
    "\n",
    "study_iso = optuna.create_study(direction='maximize')\n",
    "study_iso.optimize(objective_iso, n_trials=10) # 15 trials is enough for this\n",
    "\n",
    "print(\"Best IF Params:\", study_iso.best_params)\n",
    "best_iso_params = study_iso.best_params\n",
    "\n",
    "# Clean up memory\n",
    "del X_opt, X_opt_fraud, X_opt_normal, y_opt\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3e80801-3263-47b8-9528-86ce5dffff77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STAGE 0: Generating Scores & Filtering ---\n",
      "Scoring X_train...\n",
      "Scoring X_val & X_test...\n"
     ]
    }
   ],
   "source": [
    "print(\"--- STAGE 0: Generating Scores & Filtering ---\")\n",
    "\n",
    "# 1. Initialize Isolation Forest\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=best_iso_params['n_estimators'],\n",
    "    # Safety: If Optuna picked a float (percentage), cap it to avoid RAM crash\n",
    "    max_samples=256*1024 if isinstance(best_iso_params['max_samples'], float) else best_iso_params['max_samples'],\n",
    "    max_features=best_iso_params['max_features'],\n",
    "    n_jobs=-1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. FIT on a Subset\n",
    "# We do not need to fit on 100% of rows to learn what \"Normal\" is.\n",
    "X_fit_iso = X_train.sample(n=500000, random_state=42)\n",
    "iso_forest.fit(X_fit_iso)\n",
    "del X_fit_iso # Free memory immediately\n",
    "\n",
    "# 3. SCORE the Full Datasets\n",
    "# This attaches the 'anomaly_score' column to everyone\n",
    "print(\"Scoring X_train...\")\n",
    "X_train['anomaly_score'] = -iso_forest.decision_function(X_train)\n",
    "\n",
    "print(\"Scoring X_val & X_test...\")\n",
    "X_val['anomaly_score'] = -iso_forest.decision_function(X_val)\n",
    "X_test['anomaly_score'] = -iso_forest.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6833e45b-3012-4158-80fd-70cc03b36ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Advanced Unsupervised Features (Clustering & PCA) ---\n",
      "Using 10 features for unsupervised enrichment...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"--- Generating Advanced Unsupervised Features (Clustering & PCA) ---\")\n",
    "\n",
    "# 1. Select Key Numerical Columns\n",
    "# We use the behavioral features, as these define the \"Shape of Fraud\"\n",
    "enrich_cols = [\n",
    "    'amount', \n",
    "    'anomaly_score',\n",
    "    'credit_utilization', \n",
    "    'current_age', \n",
    "    'yearly_income_person', \n",
    "    'fico_score', \n",
    "    'trans_last_24h', \n",
    "    'amount_ratio', \n",
    "    'time_since_last_trans', \n",
    "    'diff_from_median'\n",
    "]\n",
    "\n",
    "# Safety Check: Ensure these columns exist in X_train\n",
    "available_cols = [c for c in enrich_cols if c in X_train.columns]\n",
    "if len(available_cols) < len(enrich_cols):\n",
    "    print(f\"Warning: Some columns missing. Using: {available_cols}\")\n",
    "    enrich_cols = available_cols\n",
    "\n",
    "print(f\"Using {len(enrich_cols)} features for unsupervised enrichment...\")\n",
    "\n",
    "# 2. Internal Scaling (Crucial for KMeans/PCA)\n",
    "# We use a separate scaler so we don't disturb the main dataset\n",
    "enrich_scaler = StandardScaler()\n",
    "\n",
    "# Fit on Train, Transform on all\n",
    "X_scaled_train = enrich_scaler.fit_transform(X_train[enrich_cols])\n",
    "X_scaled_val = enrich_scaler.transform(X_val[enrich_cols])\n",
    "X_scaled_test = enrich_scaler.transform(X_test[enrich_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eef15a33-58c5-4231-8438-38c04534d1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Computing Cluster Distances...\n"
     ]
    }
   ],
   "source": [
    "# --- FEATURE A: Cluster Distance (MiniBatchKMeans) ---\n",
    "print(\"1. Computing Cluster Distances...\")\n",
    "# We fit only on NORMAL data (y=0) to learn \"Normal Prototypes\"\n",
    "# We increase clusters to 20 to capture the complexity of features\n",
    "kmeans = MiniBatchKMeans(n_clusters=30, batch_size=4096, random_state=42)\n",
    "normal_mask = (y_train == 0)\n",
    "\n",
    "kmeans.fit(X_scaled_train[normal_mask])\n",
    "\n",
    "def get_cluster_dist(X_scaled, model):\n",
    "    # Calculate Euclidean distance to the nearest normal cluster center\n",
    "    dist_matrix = model.transform(X_scaled)\n",
    "    return np.min(dist_matrix, axis=1)\n",
    "\n",
    "X_train['enriched_cluster_dist'] = get_cluster_dist(X_scaled_train, kmeans)\n",
    "X_val['enriched_cluster_dist'] = get_cluster_dist(X_scaled_val, kmeans)\n",
    "X_test['enriched_cluster_dist'] = get_cluster_dist(X_scaled_test, kmeans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51b215a9-8198-4e8a-aeeb-8350b8f51e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Computing PCA Reconstruction Error...\n",
      "Enrichment Complete.\n",
      "New Features Added: ['enriched_cluster_dist', 'enriched_pca_error']\n",
      "   enriched_cluster_dist  enriched_pca_error\n",
      "0               1.868039            0.394378\n",
      "1               2.149010            0.251650\n",
      "2               1.291200            0.144403\n",
      "3               1.318528            0.165323\n",
      "4               2.058391            0.251553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- FEATURE B: PCA Reconstruction Error ---\n",
    "print(\"2. Computing PCA Reconstruction Error...\")\n",
    "# We compress 9+ dimensions down to 3, then try to reconstruct.\n",
    "# Fraud (which breaks the correlation rules of normal behavior) will have high error.\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "pca.fit(X_scaled_train[normal_mask])\n",
    "\n",
    "def get_pca_error(X_scaled, model):\n",
    "    X_low = model.transform(X_scaled)\n",
    "    X_recon = model.inverse_transform(X_low)\n",
    "    # Mean Squared Error between Original and Reconstructed\n",
    "    return np.mean(np.square(X_scaled - X_recon), axis=1)\n",
    "\n",
    "X_train['enriched_pca_error'] = get_pca_error(X_scaled_train, pca)\n",
    "X_val['enriched_pca_error'] = get_pca_error(X_scaled_val, pca)\n",
    "X_test['enriched_pca_error'] = get_pca_error(X_scaled_test, pca)\n",
    "\n",
    "print(\"Enrichment Complete.\")\n",
    "print(f\"New Features Added: ['enriched_cluster_dist', 'enriched_pca_error']\")\n",
    "print(X_train[['enriched_cluster_dist', 'enriched_pca_error']].head())\n",
    "\n",
    "# Clean up memory\n",
    "del X_scaled_train, X_scaled_val, X_scaled_test, enrich_scaler\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89c31fff-48b8-4286-97db-a4d0556f1f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>credit_utilization</th>\n",
       "      <th>current_age</th>\n",
       "      <th>yearly_income_person</th>\n",
       "      <th>fico_score</th>\n",
       "      <th>trans_last_24h</th>\n",
       "      <th>amount_ratio</th>\n",
       "      <th>state_mismatch</th>\n",
       "      <th>time_since_last_trans</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>...</th>\n",
       "      <th>mcc_risk</th>\n",
       "      <th>diff_from_median</th>\n",
       "      <th>use_chip</th>\n",
       "      <th>card_type</th>\n",
       "      <th>error_code</th>\n",
       "      <th>anomaly_score</th>\n",
       "      <th>enriched_cluster_dist</th>\n",
       "      <th>enriched_pca_error</th>\n",
       "      <th>log_amount</th>\n",
       "      <th>log_time_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>58</td>\n",
       "      <td>72510.0</td>\n",
       "      <td>727</td>\n",
       "      <td>1</td>\n",
       "      <td>1.615010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>26.895000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.069608</td>\n",
       "      <td>1.868039</td>\n",
       "      <td>0.394378</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-68.000000</td>\n",
       "      <td>-0.002006</td>\n",
       "      <td>58</td>\n",
       "      <td>72510.0</td>\n",
       "      <td>727</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.615010</td>\n",
       "      <td>0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-109.104996</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.103437</td>\n",
       "      <td>2.149010</td>\n",
       "      <td>0.251650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.042633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113.620003</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>58</td>\n",
       "      <td>72510.0</td>\n",
       "      <td>727</td>\n",
       "      <td>3</td>\n",
       "      <td>2.698492</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>72.514999</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.107945</td>\n",
       "      <td>1.291200</td>\n",
       "      <td>0.144403</td>\n",
       "      <td>4.741622</td>\n",
       "      <td>5.484797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114.730003</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>58</td>\n",
       "      <td>72510.0</td>\n",
       "      <td>727</td>\n",
       "      <td>4</td>\n",
       "      <td>2.724855</td>\n",
       "      <td>0</td>\n",
       "      <td>36540.0</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>73.625000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.117059</td>\n",
       "      <td>1.318528</td>\n",
       "      <td>0.165323</td>\n",
       "      <td>4.751260</td>\n",
       "      <td>10.506190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>251.710007</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>58</td>\n",
       "      <td>72510.0</td>\n",
       "      <td>727</td>\n",
       "      <td>2</td>\n",
       "      <td>5.978150</td>\n",
       "      <td>0</td>\n",
       "      <td>55980.0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>210.605011</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.102820</td>\n",
       "      <td>2.058391</td>\n",
       "      <td>0.251553</td>\n",
       "      <td>5.532243</td>\n",
       "      <td>10.932768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       amount  credit_utilization  current_age  yearly_income_person  \\\n",
       "0   68.000000            0.002006           58               72510.0   \n",
       "1  -68.000000           -0.002006           58               72510.0   \n",
       "2  113.620003            0.003352           58               72510.0   \n",
       "3  114.730003            0.003384           58               72510.0   \n",
       "4  251.710007            0.007425           58               72510.0   \n",
       "\n",
       "   fico_score  trans_last_24h  amount_ratio  state_mismatch  \\\n",
       "0         727               1      1.615010               0   \n",
       "1         727               2     -1.615010               0   \n",
       "2         727               3      2.698492               0   \n",
       "3         727               4      2.724855               0   \n",
       "4         727               2      5.978150               0   \n",
       "\n",
       "   time_since_last_trans      hour_sin  ...  mcc_risk  diff_from_median  \\\n",
       "0                    0.0  2.588190e-01  ...  0.000046         26.895000   \n",
       "1                  420.0  2.588190e-01  ...  0.000046       -109.104996   \n",
       "2                  240.0  2.588190e-01  ...  0.000046         72.514999   \n",
       "3                36540.0  1.224647e-16  ...  0.000206         73.625000   \n",
       "4                55980.0  7.071068e-01  ...  0.001191        210.605011   \n",
       "\n",
       "   use_chip  card_type  error_code  anomaly_score  enriched_cluster_dist  \\\n",
       "0         2          0          22      -0.069608               1.868039   \n",
       "1         2          0          22      -0.103437               2.149010   \n",
       "2         2          0          22      -0.107945               1.291200   \n",
       "3         2          0          22      -0.117059               1.318528   \n",
       "4         2          0          22      -0.102820               2.058391   \n",
       "\n",
       "   enriched_pca_error  log_amount  log_time_gap  \n",
       "0            0.394378    4.234107      0.000000  \n",
       "1            0.251650         NaN      6.042633  \n",
       "2            0.144403    4.741622      5.484797  \n",
       "3            0.165323    4.751260     10.506190  \n",
       "4            0.251553    5.532243     10.932768  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4338956-730b-4311-a509-7ea7e345178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Data Balancing (1:5 Ratio) ---\n",
      "Original Count -> Fraud: 15,395 | Normal: 12,784,605\n",
      "Data Balanced. New Training Size: 323,295 rows.\n",
      "   - Fraud: 15395\n",
      "   - Normal: 307900\n",
      "   - Ratio: 1:20\n",
      "Validation Set Size (Unchanged): 1,600,000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "print(\"--- Final Data Balancing (1:5 Ratio) ---\")\n",
    "\n",
    "# 1. Separate Fraud and Normal\n",
    "X_fraud = X_train[y_train == 1]\n",
    "X_normal = X_train[y_train == 0]\n",
    "\n",
    "print(f\"Original Count -> Fraud: {len(X_fraud):,} | Normal: {len(X_normal):,}\")\n",
    "\n",
    "# 2. Define the Ratio\n",
    "# 1:20 is the 'Golden Ratio' for fraud. \n",
    "# It gives enough 'normal' context without drowning out the fraud signals.\n",
    "target_ratio = 20 \n",
    "n_normal_samples = len(X_fraud) * target_ratio\n",
    "\n",
    "# 3. Random Undersampling\n",
    "# We pick random normal transactions. \n",
    "# (Since we have the 'anomaly_score' feature, random sampling is safe!)\n",
    "X_normal_sampled = X_normal.sample(n=n_normal_samples, random_state=42)\n",
    "\n",
    "# 4. Concatenate and Shuffle\n",
    "# Combine the sets and shuffle so the model doesn't learn order bias\n",
    "X_train_final = pd.concat([X_fraud, X_normal_sampled])\n",
    "y_train_final = pd.concat([y_train[X_fraud.index], y_train[X_normal_sampled.index]])\n",
    "\n",
    "X_train_final, y_train_final = shuffle(X_train_final, y_train_final, random_state=42)\n",
    "\n",
    "print(f\"Data Balanced. New Training Size: {len(X_train_final):,} rows.\")\n",
    "print(f\"   - Fraud: {y_train_final.sum()}\")\n",
    "print(f\"   - Normal: {len(y_train_final) - y_train_final.sum()}\")\n",
    "print(\"   - Ratio: 1:20\")\n",
    "\n",
    "# 5. Sanity Check:\n",
    "print(f\"Validation Set Size (Unchanged): {len(X_val):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "943b14a3-01fe-456b-8e67-f18e5226e136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  PHASE 2: Data Cleaning & Advanced Resampling ---\n",
      "1. Cleaning Data for SMOTE...\n",
      "   ✅ Data Cleaned. NaNs Remaining: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"---  PHASE 2: Data Cleaning & Advanced Resampling ---\")\n",
    "\n",
    "# STEP 1: DATA CLEANING (Crucial Fix for 'Input contains NaN' Error)\n",
    "\n",
    "print(\"1. Cleaning Data for SMOTE...\")\n",
    "\n",
    "# A. Fill Missing Values with 0\n",
    "# (Standard practice for 'time_since_last_trans' on first transactions)\n",
    "X_train_final = X_train_final.fillna(0)\n",
    "\n",
    "# B. Replace Infinity with 0\n",
    "X_train_final.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "# C. Safe Log-Transform Fix (Clip negatives if columns exist)\n",
    "cols_to_fix = ['log_amount', 'log_time_gap']\n",
    "for col in cols_to_fix:\n",
    "    if col in X_train_final.columns:\n",
    "        # Re-calculate logs safely: Clip negatives to 0, then log\n",
    "        original_col = col.replace('log_', '')\n",
    "        if original_col == 'time_gap': original_col = 'time_since_last_trans' \n",
    "        \n",
    "        if original_col in X_train_final.columns:\n",
    "            X_train_final[col] = np.log1p(X_train_final[original_col].clip(lower=0))\n",
    "\n",
    "print(f\"   ✅ Data Cleaned. NaNs Remaining: {X_train_final.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5612a654-808c-4a87-a518-f7de29abe36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SMOTE + Tomek ---\n",
      "Original Training Size: 323,295 rows\n",
      " SMOTE + Tomek Complete. New Size: 601826 rows\n",
      "   (This creates the 'Clear Decision Boundary')\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "print(\"--- SMOTE + Tomek ---\")\n",
    "\n",
    "# 1. Apply SMOTE + Tomek to the 1:20 Balanced Data\n",
    "# We use the dataset created earlier (X_train_final, y_train_final)\n",
    "\n",
    "print(f\"Original Training Size: {len(X_train_final):,} rows\")\n",
    "\n",
    "# smote_tomek handles both oversampling (SMOTE) and cleaning (Tomek)\n",
    "smt = SMOTETomek(random_state=42, n_jobs=-1) \n",
    "X_train_final, y_train_final = smt.fit_resample(X_train_final, y_train_final)\n",
    "\n",
    "print(f\" SMOTE + Tomek Complete. New Size: {len(X_train_final)} rows\")\n",
    "print(f\"   (This creates the 'Clear Decision Boundary')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77520ccc-563d-4f8e-b6d7-89ab700a24b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_curve\n",
    "# def objective_lgbm(trial):\n",
    "#     # 1. Hyperparameter Search Space\n",
    "#     params = {\n",
    "#         'objective': 'binary',\n",
    "#         'metric': 'None',  # We calculate our own metric\n",
    "#         'n_estimators': 1000,\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 20, 128),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 5, 12),\n",
    "#         'min_child_samples': trial.suggest_int('min_child_samples', 20, 100),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "#         'scale_pos_weight': 1, \n",
    "#         'n_jobs': -1,\n",
    "#         'verbose': -1,\n",
    "#         'random_state': 42\n",
    "#     }\n",
    "    \n",
    "#     # 2. Train Model (NO resampling, cost-sensitive params already in `params`)\n",
    "#     model = lgb.LGBMClassifier(**params)\n",
    "#     model.fit(X_train_final, y_train_final)\n",
    "    \n",
    "#     # 3. Predict on REAL Validation Set\n",
    "#     y_probs = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "#     # 4. Precision–Recall Curve\n",
    "#     prec, rec, thresholds = precision_recall_curve(y_val, y_probs)\n",
    "    \n",
    "#     # Remove the first point (precision=class prior, threshold=inf)\n",
    "#     prec = prec[1:]\n",
    "#     rec = rec[1:]\n",
    "#     thresholds = thresholds[1:]\n",
    "    \n",
    "#     # ---- SOFT PRECISION-CONSTRAINED OBJECTIVE ----\n",
    "#     target_precision = 0.5          # SOFT target, not a hard gate\n",
    "#     penalty_weight = 2.0             # how strongly to punish low precision\n",
    "    \n",
    "#     # Penalize recall when precision falls below target\n",
    "#     penalty = np.maximum(target_precision - prec, 0.0)\n",
    "    \n",
    "#     # Final score: reward recall, penalize low precision\n",
    "#     scores = rec - penalty_weight * penalty\n",
    "    \n",
    "#     # Optuna wants a scalar\n",
    "#     score = scores.max()\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# # Run Optuna\n",
    "# print(\"--- Tuning LGBM for Recall---\")\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective_lgbm, n_trials=15) \n",
    "\n",
    "# print(\"Best Recall at 20% Precision:\", study.best_value)\n",
    "# print(\"Best Params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a194c037-4c77-443d-b24a-3c8c4671fa29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.metrics import average_precision_score\n",
    "\n",
    "# print(\"--- Tuning MLP (Neural Net) for Stacking ---\")\n",
    "\n",
    "# def objective_mlp(trial):\n",
    "#     # 1. Hyperparameters\n",
    "#     # Keep layers small to prevent overfitting on 92k rows\n",
    "#     n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "#     layers = []\n",
    "#     for i in range(n_layers):\n",
    "#         layers.append(trial.suggest_int(f'n_units_l{i}', 16, 128))\n",
    "    \n",
    "#     params = {\n",
    "#         'hidden_layer_sizes': tuple(layers),\n",
    "#         'activation': 'relu',\n",
    "#         'solver': 'adam',\n",
    "#         'alpha': trial.suggest_float('alpha', 1e-5, 1e-1, log=True), # Regularization\n",
    "#         'learning_rate_init': trial.suggest_float('learning_rate_init', 1e-4, 1e-2, log=True),\n",
    "#         'max_iter': 500,  # Enough for convergence\n",
    "#         'early_stopping': True,\n",
    "#         'random_state': 42\n",
    "#     }\n",
    "    \n",
    "#     # 2. Build Pipeline (Scaling + MLP)\n",
    "#     # MLP REQUIRES Standard Scaling to work\n",
    "#     model = make_pipeline(\n",
    "#         StandardScaler(), \n",
    "#         MLPClassifier(**params)\n",
    "#     )\n",
    "    \n",
    "#     # 3. Train\n",
    "#     model.fit(X_train_final, y_train_final)\n",
    "    \n",
    "#     # 4. Evaluate (Maximize AUPRC)\n",
    "#     # We use AUPRC because we want good probability ranking for the Meta-Learner\n",
    "#     y_probs = model.predict_proba(X_val)[:, 1]\n",
    "#     score = average_precision_score(y_val, y_probs)\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# study_mlp = optuna.create_study(direction='maximize')\n",
    "# study_mlp.optimize(objective_mlp, n_trials=20) # 20 is enough for MLP\n",
    "\n",
    "# print(\"Best MLP AUPRC:\", study_mlp.best_value)\n",
    "# print(\"Best Params:\", study_mlp.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa2e36fa-084f-453c-8555-f79767336b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Assembling Final Stacking Ensemble (Auto-Configured) ---\n",
      "Fitting Final Stack on 601,826 rows...\n",
      "Saving Model & Config...\n",
      "✅ DONE. Model saved as 'app_model_stack.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import json\n",
    "\n",
    "print(\"--- Assembling Final Stacking Ensemble (Auto-Configured) ---\")\n",
    "\n",
    "# Create the MLP Pipeline\n",
    "# mlp_learner = make_pipeline(\n",
    "#     SimpleImputer(strategy=\"median\"),\n",
    "#     StandardScaler(),\n",
    "#     MLPClassifier(\n",
    "#         hidden_layer_sizes=(64, 32),   # SAFE, shallow\n",
    "#         activation='relu',\n",
    "#         solver='adam',\n",
    "#         alpha=1e-3,\n",
    "#         learning_rate_init=1e-3,\n",
    "#         max_iter=300,\n",
    "#         early_stopping=True,\n",
    "#         random_state=42\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# --- 2. Robust LightGBM (Safe Defaults) ---\n",
    "# Note: We stick to robust defaults here to avoid the precision crash we saw earlier.\n",
    "clf_lgbm = lgb.LGBMClassifier(\n",
    "    n_estimators=1500,\n",
    "    learning_rate=0.03,\n",
    "\n",
    "    num_leaves=31,\n",
    "    max_depth=6,\n",
    "    min_child_samples=300,      # CRITICAL for recall stability\n",
    "\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "\n",
    "    objective='binary',\n",
    "\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# --- 3. Robust Random Forest ---\n",
    "clf_rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=100,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- 4. Build & Train The Stack ---\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('lgbm', clf_lgbm),\n",
    "        ('rf', clf_rf)\n",
    "        #('mlp', mlp_learner)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        max_iter=500\n",
    "    ),\n",
    "    cv=3,              # OOF predictions → critical\n",
    "    n_jobs=-1,\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "print(f\"Fitting Final Stack on {len(X_train_final):,} rows...\")\n",
    "stack.fit(X_train_final, y_train_final)\n",
    "\n",
    "# --- 5. Save Artifacts ---\n",
    "print(\"Saving Model & Config...\")\n",
    "joblib.dump(stack, 'app_model_stack.pkl')\n",
    "\n",
    "feature_config = {\n",
    "    \"model_type\": \"StackingClassifier\",\n",
    "    \"features\": list(X_train_final.columns)\n",
    "}\n",
    "with open('app_config.json', 'w') as f:\n",
    "    json.dump(feature_config, f)\n",
    "\n",
    "print(\"✅ DONE. Model saved as 'app_model_stack.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ec26adf-1c63-486e-9c97-f2b019f8a981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FINAL MODEL REPORT CARD (THRESHOLD-OPTIMIZED)\n",
      "==================================================\n",
      "Stacking AUPRC: 0.0023\n",
      "\n",
      "Chosen Threshold: 0.998603\n",
      "Precision @ Threshold: 1.0000\n",
      "Recall @ Threshold:    0.0000\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9992    1.0000    0.9996   1598649\n",
      "       Fraud     0.0000    0.0000    0.0000      1351\n",
      "\n",
      "    accuracy                         0.9992   1600000\n",
      "   macro avg     0.4996    0.5000    0.4998   1600000\n",
      "weighted avg     0.9983    0.9992    0.9987   1600000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" FINAL MODEL REPORT CARD (THRESHOLD-OPTIMIZED)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Predict probabilities on REAL validation set\n",
    "# -------------------------------------------------\n",
    "y_probs_stack = stack.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. AUPRC (threshold-independent quality metric)\n",
    "# -------------------------------------------------\n",
    "auprc = average_precision_score(y_val, y_probs_stack)\n",
    "print(f\"Stacking AUPRC: {auprc:.4f}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Precision–Recall Curve\n",
    "# -------------------------------------------------\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_probs_stack)\n",
    "\n",
    "# Remove the first degenerate point (threshold = inf)\n",
    "precision = precision[1:]\n",
    "recall = recall[1:]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. THRESHOLD OPTIMIZATION STRATEGY\n",
    "#    Maximize Recall subject to Precision ≥ P_min\n",
    "# -------------------------------------------------\n",
    "P_min = 0.10   \n",
    "\n",
    "valid_idx = np.where(precision >= P_min)[0]\n",
    "\n",
    "if len(valid_idx) == 0:\n",
    "    print(\"\\n WARNING: Precision constraint not met at any threshold.\")\n",
    "    best_idx = np.argmax(recall)\n",
    "else:\n",
    "    best_idx = valid_idx[np.argmax(recall[valid_idx])]\n",
    "\n",
    "best_thresh = thresholds[best_idx]\n",
    "\n",
    "print(f\"\\nChosen Threshold: {best_thresh:.6f}\")\n",
    "print(f\"Precision @ Threshold: {precision[best_idx]:.4f}\")\n",
    "print(f\"Recall @ Threshold:    {recall[best_idx]:.4f}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Apply threshold & report\n",
    "# -------------------------------------------------\n",
    "y_pred_optimal = (y_probs_stack >= best_thresh).astype(int)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(\n",
    "    y_val,\n",
    "    y_pred_optimal,\n",
    "    target_names=['Normal', 'Fraud'],\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Confusion Matrix\n",
    "# -------------------------------------------------\n",
    "cm = confusion_matrix(y_val, y_pred_optimal)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    cbar=False\n",
    ")\n",
    "plt.title(f'Confusion Matrix (Threshold = {best_thresh:.4f})')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. Precision–Recall Curve with chosen point\n",
    "# -------------------------------------------------\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f'AUPRC = {auprc:.4f}')\n",
    "plt.scatter(\n",
    "    recall[best_idx],\n",
    "    precision[best_idx],\n",
    "    color='red',\n",
    "    zorder=5,\n",
    "    label='Chosen Operating Point'\n",
    ")\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision–Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37926953-1a8c-43d1-89d1-d8efaaab170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "print(\"=== FINAL BUSINESS VALUE ANALYSIS (Lift) ===\")\n",
    "\n",
    "# 1. Define 'Top 1%' Threshold (Riskiest Transactions)\n",
    "top1_thresh = np.percentile(y_probs_stack, 99)\n",
    "y_pred_top1 = (y_probs_stack >= top1_thresh).astype(int)\n",
    "\n",
    "# 2. Calculate Metrics\n",
    "precision_top1 = precision_score(y_val, y_pred_top1)\n",
    "recall_top1 = recall_score(y_val, y_pred_top1)\n",
    "base_rate = y_val.mean()\n",
    "\n",
    "# 3. Calculate Lift\n",
    "lift_score = precision_top1 / base_rate\n",
    "\n",
    "print(f\"Base Fraud Rate:               {base_rate:.4%}\")\n",
    "print(f\"Model Precision (Top 1%):      {precision_top1:.4%}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\" Lift Score:                  {lift_score:.2f}x\")\n",
    "print(f\" Recall at Top 1% Volume:     {recall_top1:.2%}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Interpretation: Your model is {lift_score:.1f}x more effective than random audits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1720b3-1500-4727-8548-3fe9f93157a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
