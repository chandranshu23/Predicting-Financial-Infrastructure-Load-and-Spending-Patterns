{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a76fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialization & Environment Setup\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Standard Talentum/Hadoop Environment Config\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# Packages for ORC/Avro support\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import DecimalType, LongType, IntegerType, TimestampType\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50d115c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Session with Hive Support\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Create_Financial_Spend_Analysis_Gold\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a41f076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Config Updated for maximum stability.\n"
     ]
    }
   ],
   "source": [
    "# --- Stability Configuration (CRITICAL for ORC/Hadoop Env) ---\n",
    "# 1. Disable Vectorized Reader (Avoids low-level ORC data reading crash)\n",
    "spark.conf.set(\"spark.sql.orc.enableVectorizedReader\", \"false\")\n",
    "spark.conf.set(\"spark.sql.hive.convertMetastoreOrc\", \"false\")\n",
    "\n",
    "# 2. Disable Broadcast Join (Avoids memory/shuffle crash on join)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1) \n",
    "\n",
    "# 3. Disable Spark's optimizing components (Forces safer execution path)\n",
    "spark.conf.set(\"spark.sql.cbo.enabled\", \"false\") \n",
    "spark.conf.set(\"spark.sql.codegen.wholeStage\", \"false\")\n",
    "\n",
    "# 4. Force Hive SerDe\n",
    "spark.conf.set(\"spark.sql.hive.convertMetastore\", \"false\") \n",
    "\n",
    "print(\"Spark Config Updated for maximum stability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60101b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Silver Layer tables from Hive...\n",
      "Transaction Count:24386900\n",
      "Users Count: 2000\n",
      "Cards Count: 6146\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- card_id: integer (nullable = true)\n",
      " |-- amount: decimal(10,2) (nullable = true)\n",
      " |-- use_chip: string (nullable = true)\n",
      " |-- merchant_name: string (nullable = true)\n",
      " |-- merchant_city: string (nullable = true)\n",
      " |-- merchant_state: string (nullable = true)\n",
      " |-- zip: string (nullable = true)\n",
      " |-- mcc: integer (nullable = true)\n",
      " |-- errors: string (nullable = true)\n",
      " |-- is_fraud: string (nullable = true)\n",
      " |-- transaction_timestamp: timestamp (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- person_id: string (nullable = true)\n",
      " |-- current_age: integer (nullable = true)\n",
      " |-- retirement_age: integer (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- birth_month: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- apartment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- per_capita_income_zipcode: decimal(10,2) (nullable = true)\n",
      " |-- yearly_income_person: decimal(10,2) (nullable = true)\n",
      " |-- total_debt: decimal(10,2) (nullable = true)\n",
      " |-- fico_score: integer (nullable = true)\n",
      " |-- num_credit_cards: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- card_index: integer (nullable = true)\n",
      " |-- card_brand: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- card_number: long (nullable = true)\n",
      " |-- expires: string (nullable = true)\n",
      " |-- cvv: integer (nullable = true)\n",
      " |-- has_chip: string (nullable = true)\n",
      " |-- cards_issued: integer (nullable = true)\n",
      " |-- credit_limit: decimal(10,2) (nullable = true)\n",
      " |-- year_pin_last_changed: integer (nullable = true)\n",
      " |-- card_on_dark_web: string (nullable = true)\n",
      " |-- acct_opened_month: integer (nullable = true)\n",
      " |-- acct_opened_year: integer (nullable = true)\n",
      " |-- expires_month: integer (nullable = true)\n",
      " |-- expires_year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Load Silver Data\n",
    "print(\"Loading Silver Layer tables from Hive...\")\n",
    "\n",
    "# A. Transactions\n",
    "df_trans_silver = spark.table(\"financial_db.transactions_silver\")\n",
    "# B. Users\n",
    "df_users_silver= spark.table(\"financial_db.users_silver\")\n",
    "# C. Cards\n",
    "df_cards_silver= spark.table(\"financial_db.cards_silver\")\n",
    "\n",
    "#3.Verification\n",
    "print(f\"Transaction Count:{df_trans_silver.count()}\")\n",
    "print(f\"Users Count: {df_users_silver.count()}\")\n",
    "print(f\"Cards Count: {df_cards_silver.count()}\")\n",
    "\n",
    "#4.Preview Schema to ensure types are correct\n",
    "df_trans_silver.printSchema()\n",
    "df_users_silver.printSchema()\n",
    "df_cards_silver.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "654a6176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+--------+--------------------+-------------+--------------+-----+----+--------------------+--------+---------------------+----+-----+\n",
      "|user_id|card_id|amount|use_chip|       merchant_name|merchant_city|merchant_state|  zip| mcc|              errors|is_fraud|transaction_timestamp|year|month|\n",
      "+-------+-------+------+--------+--------------------+-------------+--------------+-----+----+--------------------+--------+---------------------+----+-----+\n",
      "|    669|      3| 15.05|   Swipe|-8012891446218939321|    Arlington|            TX|76002|5812|                 N/A|      No|  2002-09-01 11:23:00|2002|    9|\n",
      "|    884|      1| 36.00|   Swipe|-1288082279022882052|   Rock Falls|            IL|61071|5499|                 N/A|      No|  2002-09-01 07:01:00|2002|    9|\n",
      "|    669|      3|-52.00|   Swipe|-1288082279022882052|    Arlington|            TX|76002|5499|                 N/A|      No|  2002-09-01 13:05:00|2002|    9|\n",
      "|    884|      1| 76.21|   Swipe| 2552240663952107054|  Apple River|            IL|61001|4111|                 N/A|      No|  2002-09-01 07:12:00|2002|    9|\n",
      "|    669|      3| 77.10|   Swipe|-1288082279022882052|    Arlington|            TX|76002|5499|                 N/A|      No|  2002-09-01 13:05:00|2002|    9|\n",
      "|    884|      1| 80.00|   Swipe|-1288082279022882052|   Rock Falls|            IL|61071|5499|                 N/A|      No|  2002-09-01 07:12:00|2002|    9|\n",
      "|    669|      3| 52.00|   Swipe|-1288082279022882052|    Arlington|            TX|76002|5499|                 N/A|      No|  2002-09-01 13:09:00|2002|    9|\n",
      "|    884|      1|-80.00|   Swipe|-1288082279022882052|   Rock Falls|            IL|61071|5499|                 N/A|      No|  2002-09-01 07:26:00|2002|    9|\n",
      "|    669|      3|131.09|   Swipe|-6016927238030630283|    Arlington|            TX|76002|4900|                 N/A|      No|  2002-09-01 16:33:00|2002|    9|\n",
      "|    884|      1| 67.47|   Swipe| 2552240663952107054|  Apple River|            IL|61001|4111|                 N/A|      No|  2002-09-01 07:53:00|2002|    9|\n",
      "|    669|      3|852.37|   Swipe| 1325201427189385167|    Arlington|            TX|76013|3132|                 N/A|      No|  2002-09-03 19:51:00|2002|    9|\n",
      "|    884|      1| 82.78|   Swipe| 3987752681791008991|     Rochelle|            IL|61068|5661|Insufficient Balance|      No|  2002-09-01 08:42:00|2002|    9|\n",
      "|    669|      3|152.00|   Swipe| 4552887027432897467|      Oakland|            CA|94606|3596|                 N/A|      No|  2002-09-04 02:01:00|2002|    9|\n",
      "|    884|      1| 77.06|   Swipe| 3987752681791008991|     Rochelle|            IL|61068|5661|                 N/A|      No|  2002-09-01 08:56:00|2002|    9|\n",
      "|    669|      3|  7.86|   Swipe|-5467922351692495955|      Corning|            NY|14830|5912|                 N/A|      No|  2002-09-07 07:38:00|2002|    9|\n",
      "|    884|      1| 12.84|   Swipe|   97032797689821735|       Roscoe|            IL|61073|5411|                 N/A|      No|  2002-09-01 11:17:00|2002|    9|\n",
      "|    669|      3|  8.50|   Swipe| 7069584154815291371|       Dundee|            NY|14837|5812|                 N/A|      No|  2002-09-08 21:03:00|2002|    9|\n",
      "|    884|      1| 43.51|   Swipe| 2552240663952107054|  Apple River|            IL|61001|4111|                 N/A|      No|  2002-09-01 13:28:00|2002|    9|\n",
      "|    669|      3|238.17|   Swipe| 4552887027432897467|      Oakland|            CA|94606|3596|                 N/A|      No|  2002-09-09 11:46:00|2002|    9|\n",
      "|    884|      1| 53.20|   Swipe|-1313671501277229753|     Rochelle|            IL|61068|5812|                 N/A|      No|  2002-09-01 21:12:00|2002|    9|\n",
      "+-------+-------+------+--------+--------------------+-------------+--------------+-----+----+--------------------+--------+---------------------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_trans_silver.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5a1f812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 3: Preparing DataFrames for Join ---\n"
     ]
    }
   ],
   "source": [
    "# 3. Data Prep & Renaming (Silver -> Gold Prep)\n",
    "print(\"--- Step 3: Preparing DataFrames for Join ---\")\n",
    "\n",
    "# --- A. Transactions Prep ---\n",
    "df_trans_prep = df_trans_silver \\\n",
    "    .withColumnRenamed(\"zip\", \"merchant_zip\") \\\n",
    "    .withColumn(\"txn_date\", F.to_date(F.col(\"transaction_timestamp\"))) \\\n",
    "    .withColumn(\"hour\", F.hour(F.col(\"transaction_timestamp\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44612e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- B. Users Prep ---\n",
    "# Generate user_id via indexing to match Schema if not present, or use existing logic\n",
    "# (Assuming the logic from your previous script is required to sync IDs)\n",
    "rdd_with_id = df_users_silver.rdd.zipWithIndex().map(lambda x: (x[1],) + tuple(x[0]))\n",
    "user_cols = [\"user_id\"] + df_users_silver.columns\n",
    "df_users_indexed = spark.createDataFrame(rdd_with_id, user_cols)\n",
    "\n",
    "df_users_prep = df_users_indexed \\\n",
    "    .withColumnRenamed(\"current_age\", \"age\") \\\n",
    "    .withColumnRenamed(\"city\", \"user_city\") \\\n",
    "    .withColumnRenamed(\"state\", \"user_state\") \\\n",
    "    .withColumnRenamed(\"yearly_income_person\", \"yearly_income\") \\\n",
    "    .withColumnRenamed(\"gender\", \"user_gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cfd42baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- C. Cards Prep ---\n",
    "df_cards_prep = df_cards_silver \\\n",
    "    .withColumnRenamed(\"user\", \"user_id\") \\\n",
    "    .withColumnRenamed(\"card_index\", \"card_id\") \\\n",
    "    .withColumnRenamed(\"card_brand\", \"card_brand\") \\\n",
    "    .withColumnRenamed(\"card_type\", \"card_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29de3fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 4: Joining Transactions + Users + Cards ---\n"
     ]
    }
   ],
   "source": [
    "# 4. Joining Data\n",
    "print(\"--- Step 4: Joining Transactions + Users + Cards ---\")\n",
    "\n",
    "# Join 1: Trans + Users\n",
    "df_join_1 = df_trans_prep.join(df_users_prep, on=\"user_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "560b4c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join 2: + Cards\n",
    "df_full_join = df_join_1.join(df_cards_prep, on=[\"user_id\", \"card_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c46cad67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 5: Feature Engineering for Spend Analysis ---\n"
     ]
    }
   ],
   "source": [
    "# 5. Spend Analysis Feature Engineering\n",
    "print(\"--- Step 5: Feature Engineering for Spend Analysis ---\")\n",
    "\n",
    "df_enriched = df_full_join.withColumn(\n",
    "    # A. Spending Brackets (Categorizing Transaction Size)\n",
    "    \"spend_tier\",\n",
    "    F.when(F.col(\"amount\") < 20, \"Micro_Spend\")\n",
    "     .when((F.col(\"amount\") >= 20) & (F.col(\"amount\") < 100), \"Low_Value\")\n",
    "     .when((F.col(\"amount\") >= 100) & (F.col(\"amount\") < 500), \"Mid_Value\")\n",
    "     .otherwise(\"High_Value\")\n",
    ").withColumn(\n",
    "    # B. Demographics Segments (For Slicing by User Type)\n",
    "    \"age_group\",\n",
    "    F.when(F.col(\"age\") < 25, \"Gen_Z\")\n",
    "     .when((F.col(\"age\") >= 25) & (F.col(\"age\") < 40), \"Millennial\")\n",
    "     .when((F.col(\"age\") >= 40) & (F.col(\"age\") < 60), \"Gen_X\")\n",
    "     .otherwise(\"Boomer_Plus\")\n",
    ").withColumn(\n",
    "    # C. Income Segments\n",
    "    \"income_tier\",\n",
    "    F.when(F.col(\"yearly_income\") < 30000, \"Low_Income\")\n",
    "     .when((F.col(\"yearly_income\") >= 30000) & (F.col(\"yearly_income\") < 80000), \"Middle_Income\")\n",
    "     .otherwise(\"High_Income\")\n",
    ").withColumn(\n",
    "    # D. Location Analysis (Domestic vs Travel Spend)\n",
    "    \"spend_location_type\",\n",
    "    F.when(F.col(\"merchant_state\") == F.col(\"user_state\"), \"Local_Spend\")\n",
    "     .when(F.col(\"merchant_state\").isNull(), \"Online/Unknown\")\n",
    "     .otherwise(\"Travel_Domestic\")\n",
    ").withColumn(\n",
    "    # E. Time Analysis (Weekend vs Weekday)\n",
    "    \"is_weekend\",\n",
    "    F.when(F.dayofweek(F.col(\"txn_date\")).isin([1, 7]), \"Weekend\") # 1=Sun, 7=Sat\n",
    "     .otherwise(\"Weekday\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a258c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 6: Aggregating to Daily Spend Fact Table ---\n"
     ]
    }
   ],
   "source": [
    "# 6. Aggregation (Creating the Gold Fact Table)\n",
    "#Spend Analysis is best viewed at a \n",
    "#Daily Level grouped by Segment. This creates a \"Daily Spend Fact\" table.\n",
    "print(\"--- Step 6: Aggregating to Daily Spend Fact Table ---\")\n",
    "\n",
    "df_gold_spend = df_enriched.groupBy(\n",
    "    \"txn_date\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"age_group\",\n",
    "    \"income_tier\",\n",
    "    \"user_gender\",\n",
    "    \"card_brand\",\n",
    "    \"card_type\",\n",
    "    \"spend_location_type\",\n",
    "    \"mcc\" # Merchant Category Code is vital for Spend Analysis\n",
    ").agg(\n",
    "    # 1. Volume Metrics\n",
    "    F.sum(\"amount\").alias(\"total_spend_amount\"),\n",
    "    F.count(\"amount\").alias(\"transaction_count\"),\n",
    "    \n",
    "    # 2. Average Metrics (ATV - Average Transaction Value)\n",
    "    F.avg(\"amount\").alias(\"avg_ticket_size\"),\n",
    "    \n",
    "    # 3. Risk/Quality Metrics\n",
    "    F.sum(F.when(F.col(\"is_fraud\") == \"Yes\", F.col(\"amount\")).otherwise(0)).alias(\"fraud_spend_amount\"),\n",
    "    \n",
    "    # 4. Max Spend (to identify big ticket items in that segment)\n",
    "    F.max(\"amount\").alias(\"max_transaction_val\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a362a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 7: Saving Gold Table ---\n",
      "SUCCESS: Spend Analysis Gold Table Saved!\n"
     ]
    }
   ],
   "source": [
    "# 7. Final Formatting & Saving\n",
    "print(\"--- Step 7: Saving Gold Table ---\")\n",
    "\n",
    "# Define Path (Using similar path structure as your reference)\n",
    "gold_spend_path = \"/user/talentum/projectMaster/warehouseDir/gold/financial_spend_analysis\"\n",
    "\n",
    "# Drop Table if exists to ensure clean overwrite\n",
    "spark.sql(\"DROP TABLE IF EXISTS financial_db.spend_analysis_gold\")\n",
    "\n",
    "# Write to Hive (ORC Format)\n",
    "df_gold_spend.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"orc\") \\\n",
    "    .option(\"path\", gold_spend_path) \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .saveAsTable(\"financial_db.spend_analysis_gold\")\n",
    "\n",
    "print(\"SUCCESS: Spend Analysis Gold Table Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddd01282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previewing Data:\n",
      "+----------+----+-----+-----------+-------------+-----------+----------+---------------+-------------------+----+------------------+-----------------+---------------+------------------+-------------------+\n",
      "|txn_date  |year|month|age_group  |income_tier  |user_gender|card_brand|card_type      |spend_location_type|mcc |total_spend_amount|transaction_count|avg_ticket_size|fraud_spend_amount|max_transaction_val|\n",
      "+----------+----+-----+-----------+-------------+-----------+----------+---------------+-------------------+----+------------------+-----------------+---------------+------------------+-------------------+\n",
      "|2020-02-28|2020|2    |Gen_Z      |Middle_Income|Male       |Visa      |Debit (Prepaid)|Online/Unknown     |5311|25.47             |1                |25.470000      |0.00              |25.47              |\n",
      "|2020-02-28|2020|2    |Gen_Z      |Middle_Income|Male       |Mastercard|Debit          |Online/Unknown     |4121|29.16             |1                |29.160000      |0.00              |29.16              |\n",
      "|2020-02-28|2020|2    |Gen_X      |Middle_Income|Male       |Mastercard|Debit          |Local_Spend        |5941|62.26             |1                |62.260000      |0.00              |62.26              |\n",
      "|2020-02-28|2020|2    |Gen_X      |Low_Income   |Female     |Visa      |Debit (Prepaid)|Local_Spend        |5541|3.17              |1                |3.170000       |0.00              |3.17               |\n",
      "|2020-02-28|2020|2    |Gen_X      |Middle_Income|Female     |Visa      |Debit          |Online/Unknown     |4121|137.80            |4                |34.450000      |0.00              |50.45              |\n",
      "|2020-02-28|2020|2    |Gen_X      |Middle_Income|Female     |Visa      |Debit          |Online/Unknown     |4722|470.51            |1                |470.510000     |0.00              |470.51             |\n",
      "|2020-02-28|2020|2    |Boomer_Plus|Low_Income   |Male       |Mastercard|Credit         |Local_Spend        |5310|21.76             |1                |21.760000      |0.00              |21.76              |\n",
      "|2020-02-28|2020|2    |Boomer_Plus|Middle_Income|Female     |Mastercard|Debit (Prepaid)|Local_Spend        |5814|7.71              |1                |7.710000       |0.00              |7.71               |\n",
      "|2020-02-28|2020|2    |Gen_X      |Middle_Income|Male       |Visa      |Debit          |Local_Spend        |7832|28.68             |1                |28.680000      |0.00              |28.68              |\n",
      "|2020-02-28|2020|2    |Boomer_Plus|Middle_Income|Male       |Discover  |Credit         |Local_Spend        |5311|2.17              |1                |2.170000       |0.00              |2.17               |\n",
      "+----------+----+-----+-----------+-------------+-----------+----------+---------------+-------------------+----+------------------+-----------------+---------------+------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Preview ---\n",
    "print(\"Previewing Data:\")\n",
    "df_gold_spend.orderBy(F.col(\"txn_date\").desc()).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f029885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
