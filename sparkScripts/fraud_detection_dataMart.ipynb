{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00487cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# NOTE: Whichever package you want mention here.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell' \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42297d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "#1. Create spark session obj\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"create_fraud_detection_dataMart\").config(\"spark.driver.memory\", \"8g\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# On yarn:\n",
    "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
    "# specify .master(\"yarn\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734344ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Config Updated for maximum stability.\n"
     ]
    }
   ],
   "source": [
    "# 1. Disable Vectorized Reader (Avoids low-level ORC data reading crash)\n",
    "spark.conf.set(\"spark.sql.orc.enableVectorizedReader\", \"false\")\n",
    "spark.conf.set(\"spark.sql.hive.convertMetastoreOrc\", \"false\")\n",
    "# 2. Disable Broadcast Join (Avoids memory/shuffle crash on join)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1) \n",
    "# 3. Disable Spark's optimizing components (Forces safer execution path)\n",
    "spark.conf.set(\"spark.sql.cbo.enabled\", \"false\") \n",
    "spark.conf.set(\"spark.sql.codegen.wholeStage\", \"false\")\n",
    "# 4. Force Hive SerDe (Ultimate attempt to bypass native Spark reader)\n",
    "spark.conf.set(\"spark.sql.hive.convertMetastore\", \"false\") \n",
    "\n",
    "print(\"Spark Config Updated for maximum stability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615a22f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField,DoubleType , IntegerType, StringType, DecimalType, TimestampType, BooleanType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141e3abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Silver Layer tables from Hive...\n",
      "Transactions Count: 24386900\n",
      "Users Count: 2000\n",
      "Cards Count: 6146\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- card_id: integer (nullable = true)\n",
      " |-- amount: decimal(10,2) (nullable = true)\n",
      " |-- use_chip: string (nullable = true)\n",
      " |-- merchant_name: string (nullable = true)\n",
      " |-- merchant_city: string (nullable = true)\n",
      " |-- merchant_state: string (nullable = true)\n",
      " |-- zip: string (nullable = true)\n",
      " |-- mcc: integer (nullable = true)\n",
      " |-- errors: string (nullable = true)\n",
      " |-- is_fraud: string (nullable = true)\n",
      " |-- transaction_timestamp: timestamp (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- person_id: string (nullable = true)\n",
      " |-- current_age: integer (nullable = true)\n",
      " |-- retirement_age: integer (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- birth_month: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- apartment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- per_capita_income_zipcode: decimal(10,2) (nullable = true)\n",
      " |-- yearly_income_person: decimal(10,2) (nullable = true)\n",
      " |-- total_debt: decimal(10,2) (nullable = true)\n",
      " |-- fico_score: integer (nullable = true)\n",
      " |-- num_credit_cards: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- card_index: integer (nullable = true)\n",
      " |-- card_brand: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- card_number: integer (nullable = true)\n",
      " |-- expires: string (nullable = true)\n",
      " |-- cvv: integer (nullable = true)\n",
      " |-- has_chip: string (nullable = true)\n",
      " |-- cards_issued: integer (nullable = true)\n",
      " |-- credit_limit: decimal(10,2) (nullable = true)\n",
      " |-- year_pin_last_changed: integer (nullable = true)\n",
      " |-- card_on_dark_web: string (nullable = true)\n",
      " |-- acct_opened_month: integer (nullable = true)\n",
      " |-- acct_opened_year: integer (nullable = true)\n",
      " |-- expires_month: integer (nullable = true)\n",
      " |-- expires_year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Load the Tables directly from the Database\n",
    "# We use the standard 'database_name.table_name' format\n",
    "\n",
    "print(\"Loading Silver Layer tables from Hive...\")\n",
    "\n",
    "# A. Transactions Table\n",
    "df_trans_silver = spark.table(\"financial_db.transactions_silver\")\n",
    "\n",
    "# B. Users Table\n",
    "df_users_silver = spark.table(\"financial_db.users_silver\")\n",
    "\n",
    "# C. Cards Table\n",
    "df_cards_silver = spark.table(\"financial_db.cards_silver\")\n",
    "\n",
    "# 3. Quick Verification\n",
    "print(f\"Transactions Count: {df_trans_silver.count()}\")\n",
    "print(f\"Users Count: {df_users_silver.count()}\")\n",
    "print(f\"Cards Count: {df_cards_silver.count()}\")\n",
    "\n",
    "# 4.Preview Schema to ensure types are correct\n",
    "df_trans_silver.printSchema()\n",
    "df_users_silver.printSchema()\n",
    "df_cards_silver.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13346322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. Fixing Users Table ---\n",
      "Users Table Prepped (Income Strictly Cleaned).\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 2. Fixing Users Table ---\")\n",
    "\n",
    "# 1. Generate 'user_id' using Row Number (0, 1, 2...)\n",
    "rdd_with_id = df_users_silver.rdd.zipWithIndex().map(lambda x: (x[1],) + tuple(x[0]))\n",
    "\n",
    "# 2. Create DataFrame with 'user_id' as the first column\n",
    "new_column_names = [\"user_id\"] + df_users_silver.columns\n",
    "df_users_indexed = spark.createDataFrame(rdd_with_id, new_column_names)\n",
    "\n",
    "# 3. Select and Rename (Strict Cleaning of Income)\n",
    "df_users_prep = df_users_indexed.select(\n",
    "    F.col(\"user_id\"),\n",
    "    F.col(\"person_id\").alias(\"person_name\"),\n",
    "    F.col(\"current_age\"),\n",
    "    F.coalesce(\n",
    "        F.regexp_replace(F.col(\"yearly_income_person\").cast(\"string\"), \"[^0-9\\\\.\\\\-]\", \"\").cast(\"double\"), \n",
    "        F.lit(0.0)\n",
    "    ).alias(\"yearly_income\"),\n",
    "    F.col(\"fico_score\"),\n",
    "    F.col(\"state\").alias(\"user_home_state\")\n",
    ")\n",
    "\n",
    "print(\"Users Table Prepped (Income Strictly Cleaned).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b9603e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3. Prep Transactions & Cards ---\n",
      "Transactions & Cards Prepped (Schema Updated).\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 3. Prep Transactions & Cards ---\")\n",
    "\n",
    "# A. Prepare Transactions\n",
    "df_trans_prep = df_trans_silver.select(\n",
    "    F.col(\"user_id\"),     \n",
    "    F.col(\"card_id\"),     \n",
    "    F.col(\"transaction_timestamp\"),\n",
    "    F.col(\"merchant_name\"),\n",
    "    F.col(\"merchant_state\"),\n",
    "    F.col(\"zip\"),         # Zip is already string in Silver, so strictly taking it is fine\n",
    "    F.col(\"mcc\").alias(\"merchant_category\"), \n",
    "    F.col(\"errors\").alias(\"error_code\"), \n",
    "    F.col(\"use_chip\"),\n",
    "    F.coalesce(F.col(\"amount\").cast(\"double\"), F.lit(0.0)).alias(\"amount\"),\n",
    "    F.when(F.col(\"is_fraud\") == \"Yes\", 1).otherwise(0).alias(\"label_is_fraud\")\n",
    ").withColumn(\"hour_of_day\", F.hour(F.col(\"transaction_timestamp\")))\n",
    "\n",
    "# B. Prepare Cards\n",
    "df_cards_prep = df_cards_silver.select(\n",
    "    F.col(\"user\").alias(\"user_id\"),\n",
    "    F.col(\"card_index\").alias(\"card_id\"),\n",
    "    F.col(\"card_brand\"),\n",
    "    F.col(\"card_type\"),\n",
    "    F.coalesce(F.col(\"credit_limit\").cast(\"double\"), F.lit(0.0)).alias(\"credit_limit\")\n",
    ")\n",
    "\n",
    "print(\"Transactions & Cards Prepped (Schema Updated).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "013960c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4. Performing Joins ---\n",
      "Joined Data Count: 24386900\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 4. Performing Joins ---\")\n",
    "\n",
    "df_join_1 = df_trans_prep.join(\n",
    "    df_users_prep,\n",
    "    on=[\"user_id\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_final_join = df_join_1.fillna(0, subset=[\"card_id\"]).join(\n",
    "    df_cards_prep,\n",
    "    on=[\"user_id\", \"card_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"Joined Data Count: {df_final_join.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39e54662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4. Advanced Feature Engineering (Post-Join) ---\n",
      "Feature Engineering Complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 4. Advanced Feature Engineering (Post-Join) ---\")\n",
    "\n",
    "df_mart = df_final_join.withColumn(\n",
    "    # 1. Composite Transaction ID\n",
    "    \"transaction_id\",\n",
    "    F.concat_ws(\"-\", F.col(\"user_id\"), F.col(\"card_id\"), F.col(\"transaction_timestamp\").cast(\"long\"))\n",
    ").withColumn(\n",
    "    # 2. Credit Utilization\n",
    "    \"credit_utilization\",\n",
    "    F.when(F.col(\"credit_limit\").cast(\"double\") > 0, \n",
    "           F.col(\"amount\").cast(\"double\") / F.col(\"credit_limit\").cast(\"double\")\n",
    "    ).otherwise(0.0)\n",
    ").withColumn(\n",
    "    # 3. State Mismatch\n",
    "    \"state_mismatch\",\n",
    "    F.when(\n",
    "        (F.col(\"merchant_state\").isNotNull()) & \n",
    "        (F.col(\"merchant_state\") != F.col(\"user_home_state\")),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ").withColumn(\n",
    "    # 4. Clean Error Codes\n",
    "    \"error_code_clean\",\n",
    "    F.coalesce(F.col(\"error_code\"), F.lit(\"None\"))\n",
    ")\n",
    "\n",
    "print(\"Feature Engineering Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f7691be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5. Final Column Selection & Save ---\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DecimalType, IntegerType\n",
    "\n",
    "print(\"--- 5. Final Column Selection & Save ---\")\n",
    "\n",
    "final_columns = [\n",
    "    # Identifiers\n",
    "    \"transaction_id\",\n",
    "    F.col(\"user_id\").alias(\"user_id\"),\n",
    "    F.col(\"card_id\").alias(\"card\"),\n",
    "    F.col(\"merchant_name\").alias(\"merchant_id\"),\n",
    "    \n",
    "    # Target\n",
    "    \"label_is_fraud\",\n",
    "    \n",
    "    # Features (Stable Decimal Casts)\n",
    "    F.col(\"amount\").cast(DecimalType(20, 4)).cast(DecimalType(10,2)).alias(\"amount\"), \n",
    "    \"hour_of_day\",\n",
    "    \"use_chip\",\n",
    "    F.col(\"merchant_category\").alias(\"merchant_category\"),\n",
    "    F.col(\"error_code_clean\").alias(\"error_code\"),\n",
    "    \"credit_utilization\",\n",
    "    \"state_mismatch\",\n",
    "    \n",
    "    # User Profile (Stable Integer Casts)\n",
    "    F.col(\"current_age\").cast(IntegerType()).alias(\"current_age\"),\n",
    "    # Stable Decimal Cast for income\n",
    "    F.col(\"yearly_income\").cast(DecimalType(20, 4)).cast(DecimalType(10,2)).alias(\"yearly_income_person\"),\n",
    "    F.col(\"fico_score\").cast(IntegerType()).alias(\"fico_score\"),\n",
    "    \n",
    "    # Card Profile\n",
    "    \"card_type\",\n",
    "    \"card_brand\"\n",
    "]\n",
    "\n",
    "df_gold_fraud = df_mart.select(*final_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a75b25f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transaction_id: string (nullable = false)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- card: integer (nullable = true)\n",
      " |-- merchant_id: string (nullable = true)\n",
      " |-- label_is_fraud: integer (nullable = false)\n",
      " |-- amount: decimal(10,2) (nullable = true)\n",
      " |-- hour_of_day: integer (nullable = true)\n",
      " |-- use_chip: string (nullable = true)\n",
      " |-- merchant_category: integer (nullable = true)\n",
      " |-- error_code: string (nullable = false)\n",
      " |-- credit_utilization: double (nullable = true)\n",
      " |-- state_mismatch: integer (nullable = false)\n",
      " |-- current_age: integer (nullable = true)\n",
      " |-- yearly_income_person: decimal(10,2) (nullable = true)\n",
      " |-- fico_score: integer (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- card_brand: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_gold_fraud.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d53ac5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 6: Saving as External Hive Table ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Step 6: Saving as External Hive Table ---\")\n",
    "# Path for the External Table\n",
    "gold_path = \"/user/talentum/projectMaster/warehouseDir/gold/fraud_detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45276308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark.conf.set(\"spark.sql.orc.enableVectorizedReader\", \"false\")\n",
    "spark.conf.set(\"spark.sql.hive.convertMetastoreOrc\", \"false\")\n",
    "\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS financial_db.fraud_detection_gold\")\n",
    "\n",
    "# Write with explicit partitioning and Hive serde override\n",
    "df_gold_fraud.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"orc\") \\\n",
    "    .option(\"path\", \"/user/talentum/projectMaster/warehouseDir/gold/fraud_detection\") \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .saveAsTable(\"financial_db.fraud_detection_gold\")\n",
    "\n",
    "print(\"SUCCESS: Table saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62610e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+----+--------------------+--------------+------+-----------+--------+-----------------+----------+--------------------+--------------+-----------+--------------------+----------+---------+----------+\n",
      "|  transaction_id|user_id|card|         merchant_id|label_is_fraud|amount|hour_of_day|use_chip|merchant_category|error_code|  credit_utilization|state_mismatch|current_age|yearly_income_person|fico_score|card_type|card_brand|\n",
      "+----------------+-------+----+--------------------+--------------+------+-----------+--------+-----------------+----------+--------------------+--------------+-----------+--------------------+----------+---------+----------+\n",
      "|196-0-1225502940|    196|   0|-5475680618560174533|             0| 45.50|          6|   Swipe|             5942|       N/A|0.002402703701747901|             0|         37|            44976.00|       684|    Debit|Mastercard|\n",
      "|196-0-1225517160|    196|   0|-8008411881496762060|             0|154.57|         10|   Swipe|             8011|       N/A|0.008162327718223584|             0|         37|            44976.00|       684|    Debit|Mastercard|\n",
      "|196-0-1225524660|    196|   0|-5841929396161652653|             0|  7.07|         13|  Online|             4121|       N/A|3.733431905792892E-4|             0|         37|            44976.00|       684|    Debit|Mastercard|\n",
      "|196-0-1225595940|    196|   0| 3048709552883112909|             0| 44.25|          8|   Swipe|             7230|       N/A|0.002336695358293...|             0|         37|            44976.00|       684|    Debit|Mastercard|\n",
      "|196-0-1225611600|    196|   0|-3529407262473201415|             0|  7.69|         13|   Swipe|             4121|       N/A|4.060833289327771...|             0|         37|            44976.00|       684|    Debit|Mastercard|\n",
      "+----------------+-------+----+--------------------+--------------+------+-----------+--------+-----------------+----------+--------------------+--------------+-----------+--------------------+----------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_gold_fraud.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3ec74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
